<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="author: T. Ruotsalo et al. Note Authored by:: [[P- Brendan Langen]]
Interactive Intent Modeling for Exploratory Search Core Questions [[Q- How do we enable users to find what they&rsquo;re looking for when they are exploring a new area]]?"><title>R- Interactive Intent Modeling for Exploratory Search</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://scalingsynthesis.com//icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><link href=https://scalingsynthesis.com/styles.1f3ba0591100ba30cb2264971dd1e99b.min.css rel=stylesheet><script src=https://scalingsynthesis.com/js/darkmode.46b07878b7f5d9e26ad7a3c40f8a0605.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script src=https://scalingsynthesis.com/js/popover.288199e63b3f94c382ad0a682c368d9d.min.js></script>
<script>const BASE_URL="https://scalingsynthesis.com/",fetchData=Promise.all([fetch("https://scalingsynthesis.com/indices/linkIndex.7550a008bcc8b2147f80c1286b5061d4.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://scalingsynthesis.com/indices/contentIndex.aa817a639c402ca26100a094d1a2fb16.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),draw=()=>{initPopover("https://scalingsynthesis.com",!0),renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script>window.navigate=e=>window.location.href=e,draw()</script><script>window.navigate=e=>window.location.href=e</script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-5P7KT5C8ET"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-5P7KT5C8ET",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://scalingsynthesis.com/js/search.1b393cefe641096453553b4a9b1c5f30.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://scalingsynthesis.com/>ðŸª´ Scaling Synthesis</a></h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>R- Interactive Intent Modeling for Exploratory Search</h1><p class=meta>Last updated May 21, 2022</p><ul class=tags></ul><p>author: T. Ruotsalo et al.
Note Authored by:: <a href=/P-Brendan-Langen rel=noopener class=internal-link data-src=/P-Brendan-Langen>P- Brendan Langen</a></p><a href=#interactive-intent-modeling-for-exploratory-search><h3 id=interactive-intent-modeling-for-exploratory-search><span class=hanchor arialabel=Anchor># </span>Interactive Intent Modeling for Exploratory Search</h3></a><a href=#core-questions><h4 id=core-questions><span class=hanchor arialabel=Anchor># </span>Core Questions</h4></a><p><a class="internal-link broken">Q- How do we enable users to find what they&rsquo;re looking for when they are exploring a new area</a>?</p><ul><li><a class="internal-link broken">C- Users struggle to formulate queries in exploratory search tasks</a>.<blockquote><p>Current interaction methods for supporting exploratory search are based on techniques that suggest terms or rephrased queries [62], document relevance feedback mechanisms [61], and faceted search interfaces that enable narrowing down the search within the initial query scope [104, 125]. These techniques put the user in a reactive role to filter search results rather than offering interaction affordances to actively direct the exploratory search process.
As a consequence, an important goal of an information retrieval system is to assist the user in understanding and specifying his/her information needs [50]. In particular, when users are engaged in complex tasks, search may not be best supported with simplistic search user interfaces and ranking optimized to maximize relevance to a single query, but rather users are engaged with the system to maximize whole-session relevance [90].</p></blockquote></li></ul><p><a class="internal-link broken">Q- How do we design search systems that evolve with user knowledge of a topic</a>?</p><ul><li><p><a class="internal-link broken">C- An exploratory search system should help the reader cumulatively gain information</a>.</p><blockquote><p>Recent results suggest that systems leveraging knowledge about a userâ€™s search intentions can provide higher quality task outcomes on a longer term, than systems that try to optimize the immediate results set against the present query [1, 41, 119].
A search system best supporting the scientist to accomplish such a task would allow a dialogue between the system and the user to not only retrieve relevant results for a particular query but to also assist in discovering related information, conceptualizing the relevant information space for comprehending the available information, and helping to specify search intents that evolve throughout the course of the task when users learn and gain information.
In exploratory search, what is encountered along the exploration affects the search intents and goals. Consequently, the system must provide the user with affordances to comprehend the information space, direct the search, and engage the user in the exploration process.
At the same time, the system can learn from user interactions to assist the user in accomplishing the userâ€™s task. Achieving a common understanding about search intents and goals requires an intrinsic interplay between the user and the information retrieval system.</p></blockquote></li><li><p><a class="internal-link broken">C- Interacting with visualizations improves task performance in exploratory searches</a>.</p><blockquote><p>Our experiments, however, suggest that interactive visualization of search intentions improves user performance without compromising search effort.
We believe it is evidence that users are able to process the information presented to them and provide effective feedback to the system. Together with the improved results in task and retrieval performance, fast and effective interaction shows that user can make efficient and effective decisions and that these decisions are beneficial for their task performance.
The technical realization of the approach by using reinforcement learning with rewards obtained from user interactions and the effectiveness of the intent model for retrieval and the visualization for search result comprehension can be applied to information seeking beyond the present studies, for example, information exploration on the Web.
Effective presentation of search results is important in exploratory information search scenarios where a user tries to gain understanding of a topic to retrieve more specific or related information in subsequent search iterations [75, 114]
Successfully comprehending information content across search results lets the user relate the result documents to each other, the query, and the underlying information need, and to exploit the information content appropriately in further processing of the found information [64]..
&mldr;in general, we lack understanding of the benefits of the visualizations. Visualizations can possibly improve usersâ€™ effectiveness or efficiency in understanding or comprehending the information collections, or alternatively act as complex proxies for simpler interactions that the users perform as a part of their information exploration processes.</p></blockquote><ul><li>Screenshot of Visualization with a query of &lsquo;computer vision&rsquo; (IntentRadar)<ul><li><img src="/Interactive intent modeling search circle.png" title="/Interactive intent modeling search circle.png"></li></ul></li><li>Example of Interactive Intent Modeling in the Visualization (IntentRadar)<ul><li><img src="/CleanShot 2022-05-21 at 16.17.36@2x.png" title="/CleanShot 2022-05-21 at 16.17.36@2x.png"></li></ul></li></ul></li><li><p><a class="internal-link broken">I- A search engine with interactive intent modeling can update based on user understanding and aid comprehension</a>.</p></li><li><p><a class="internal-link broken">C- Updating search results via interactive intent modeling improves user comprehension during exploratory searches</a>.</p><blockquote><p>Our results indicate that the retrieval performance of the system is improved as a result of interactive intent modeling. Retrieval performance is not dependent on the type of visualization and can be attributed to the intent modeling.
Interactive intent modeling is a technique that models the userâ€™s evolving search intents over a search session. The model learns intent estimates from user feedback and visualizes them as keywords for interaction as shown in Figure 1. Consequently, interactive intent modeling forms an interactive loop between the system and the user to refine the userâ€™s search intentions and direct the search process.
At each iteration, a set of keywords is suggested to the user based on the feedback obtained in previous iterations. Given the evolutionary nature of exploratory search, it is important to exploit the feedback elicited from the user but also to balance it with exploration. Users must be able to focus on a specific subset of the documents (exploit), but at the same time to be able to broaden their search to more general, but still highly relevant, documents (explore). This learning procedure is called the exploration/exploitation tradeoff of reinforcement learning.
Assisting the user in directing the search, the visualization shows both the current intent estimate, the alternative intents, and how the alternatives are related to the current intent estimate. The two-dimensional visualization shows the relevance of each keyword in the current estimated intent and the similarity of the keywords representing alternative intents.</p></blockquote><ul><li>Search Engine Comparison<ul><li><img src="/CleanShot 2022-05-21 at 16.18.11@2x.png" title="/CleanShot 2022-05-21 at 16.18.11@2x.png"></li></ul></li></ul></li><li><p><a class="internal-link broken">C- Visualizing the intent model improves task performance and comprehension without increasing effort</a>.</p><blockquote><p>Our results suggest that exploratory search can benefit from visual search support. Support for concept recovery and mental work in the form of visually-supported reasoning in the visual space suggest opportunities for improved task outcomes and improved retrieval performance over the session.
These findings suggest that visualized models can provide the users affordances, not only to direct their search but also to make sense of the information potentially available. The users also take advantage of these affordances without compromising the time spent between interactions.</p></blockquote><ul><li>User Interface with Visualization<ul><li><img src="/CleanShot 2022-05-21 at 16.18.43@2x.png" title="/CleanShot 2022-05-21 at 16.18.43@2x.png"></li></ul></li><li>User Interface with No Visualization<ul><li><img src="/CleanShot 2022-05-21 at 16.18.51@2x.png" title="/CleanShot 2022-05-21 at 16.18.51@2x.png"></li></ul></li></ul></li></ul><p><a class="internal-link broken">C- Current search engines are effective for specific informational searches</a>.</p><blockquote><p>The current generation of information retrieval systems, such as the major Web search engines, is effective at identifying a small set of the most relevant documents given a well specified information need. However, it is easy to identify many situations where more complex exploratory search support is required and increasing real-world evidence suggests that users are struggling with exploratory search [81].</p></blockquote><p>Brendan Notes
<a class="internal-link broken">Q- How can we retroactively provide users with new information related to their past searches</a>?</p><p><a class="internal-link broken">I- New findings can be pushed to a user based on their search history</a>.</p><p><a class="internal-link broken">Q- In what situations does having more information decrease user confidence</a>?</p><a href=#methodology><h6 id=methodology><span class=hanchor arialabel=Anchor># </span>Methodology</h6></a><p>Their process differs from past attempts because:</p><ol><li>They actually allow the user to visualize alongside their search, instead of looking at queries or documentation</li><li>They implement the experiment in a practical manner alongside a real-life data collection.</li><li>They empircally validate the performance in situ, instead of against log files or artificial sessions.</li></ol><a href=#experiment-design--results><h6 id=experiment-design--results><span class=hanchor arialabel=Anchor># </span>Experiment Design + Results</h6></a><p>Experiment 1 - Exploratory Search</p><ul><li>30 graduate students with technical backgrounds, familiar with literature searches, from 2 universities</li><li></li></ul><blockquote><p>The task was defined as a scientific writing scenario, i.e., the participants were asked to prepare materials and an outline for writing an essay on a given topic. The assignments were:
> (1) Search for relevant articles to be used as references in the essay.
> (2) Search for relevant keywords representing topics to be used to structure the essay</p></blockquote><blockquote><p>An interesting insight is that for the IntentRadar system, precision is slightly increasing toward the end of the session for novel documents. This suggests that richer interaction becomes crucial to discover novel information, in particular for these exploratory tasks that were studied in the experiment.
This suggests that even though the participants were shown more keywords in the IntentRadar system, they were able to select relevant keywords from the display.
Interestingly, the participants who used the IntentRadar system were significantly less convinced that they had found the right articles during the task. Given that the retrieval effectiveness was found to be significantly better for the IntentRadar system, and therefore the responses from the system were of better quality, a possible explanation is that because of the visualization the participants became more aware of other potentially relevant directions that they could not explore in the given time, and therefore might have been more informed about potentially relevant, but not yet explored, topics.</p></blockquote><p>Experiment 2 - Information Comprehension</p><ul><li>24 graduate students with technical backgrounds, from 2 universities</li></ul><blockquote><p>the focus of the study was threefold. First, to study if the visualization would assist users in the comprehension process. Second, to study if the users preferred interaction with the visualization. Third, if the visualization would improve the output of the comprehension process.
RQ5 Comprehension process: Do participants in the visualization condition inspect the search result space using the visualization more often than using the result list?
RQ6 Interaction support: Do participants in the visualization condition select keywords from the visualization more often than from the result list?
RQ7 Comprehension outcome: Does the visualization result in improved information comprehension outcome?
RQ8 User Experience: Does the result presentation using the visualization result in improved user experience?</p></blockquote></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/R-Information-Foraging-Video/ data-ctx="R- Interactive Intent Modeling for Exploratory Search" data-src=/R-Information-Foraging-Video class=internal-link>R- Information Foraging Video</a></li></ul></div></div><div id=contact_buttons><footer><p>Made by Rob Haisfield, Joel Chan, Brendan Langen using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2022</p><ul><li><a href=/>Home</a></li><li><a href=https://twitter.com/RobertHaisfield>Twitter</a></li><li><a href=https://github.com/classicrob/quartz>Github</a></li></ul></footer></div><script defer src=https://cdn.commento.io/js/commento.js></script><div id=commento></div></div></body></html>