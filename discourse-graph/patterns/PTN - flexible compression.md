---
title: [[PTN]] - flexible compression
url: https://roamresearch.com/#/app/megacoglab/page/4_VKjPZ-l
author: Joel Chan
date: Tue Feb 11 2020 13:22:09 GMT-0500 (Eastern Standard Time)
---

- key inspirations:

    - [[@luttersBoundaryObjectsCollaborative2007]]

        - Concept of [[punctuated crystallization]]: [[[[PTN]] - boundary object]]s that exist within information flows in organizations that get "crystallized" into temporary static artifacts. To understand object, must understand its place in the flow of information/work, past and future, and how it changes.

    - [[@changSupportingMobileSensemaking2016]]

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FzQl7Xo1Ckc.png?alt=media&token=a8f7e809-957b-49a8-80e0-23e958f6f9a4) (p. 61)
- UsedIn:: [[[[ART]] - Knowledge Compressor]], also seen in [[[[ART]] - LiquidText]]; and a component of [[[[ART]] - [[D/Synthesis Infrastructure]] Roam discourse graph extension]]

###### Discourse Context

- **UsedIn::** [[ART - DSynthesis Infrastructure Roam discourse graph extension]]
- **UsedIn::** [[ART - Knowledge Compressor]]
- **UsedIn::** [[ART - LiquidText]]
- **Informed By::** [[@luttersBoundaryObjectsCollaborative2007]]
- **Informed By::** [[@changSupportingMobileSensemaking2016]]

###### References

[[August 2nd, 2020]]

- the stuff about [[[[PTN]] - flexible compression]] still apply.

    - context hooks and so on in the [[epistemic foundation layer]]

    - [[context queries]] in the [[epistemic synthesis layer]]
[[August 2nd, 2020]]

- one key dimension of risk we can control: is tehre any reaosn to believe that we can get perofrmance that is reaosnable enough to support valuable [[context queries]] operations (and [[[[PTN]] - flexible compression]]?)

    - need to identify sections

        - then within sections, identify things "likely to be answer for [[context]] query x"

        - doesn't need to be perfect (can prioritize recall over precision) bc we verify at [[context queries]] time

            - also preioritize recall over precision bc [[[[CLM]] - Specifying context for future reuse requires predicting trajectories of future reuse]]

    - get SOTA code if we can for some major approaches

        - [[Jodi Schneider]]

        - [[Catherine Blake]]

            - claim extraction is challenging, but we're not trying to solve that; that's the job of the reader! what we try to do is basically do some kind of specialized [[information extraction]]

                - which is probably quite a bit easier

                    - things like author, affiliation, year, method used (lots of leverage if there is some maturity in field, as long as there is at least a methods textbook we have [[distant supervision]], at minimum we probably have some kind of methods section)
[[Grant proposal for Synthesis Infrastructure - NSF CHS  SOS 2020]]

- Deeper thinking about [[context]] and the details of [[[[PTN]] - flexible compression]]

    - {{embed: Watched [[The Bit Player]] documentary on [[Claude Shannon]]. Inspiring! Thinking again about [[compression]] in the [[information theory]] sense, and what that might mean for [[D/Synthesis Infrastructure]].}}

    - {{embed: Thinking again about [[context]] and [[[[PTN]] - flexible compression]].}}

    - {{embed: Since ((tGg1VaCU_))}}
[[May 25th, 2020]]

- This sparks a reinterpretation of the [[chunk decomposition]] stuff: they're arguments for a __specific__ form of [[Atomicity]], namely a kind of reversible or [[[[PTN]] - flexible compression]]: because the "level" of [[Atomicity]] is context-dependent, it is imperative that chunks are not too "tight".

    - Spawned this revision to #[[[[CLM]] - Compression is necessary for synthesis]]: We see this chiefly from the literature on [[Insight problem solving]], which informs us that [[[[CLM]] - Breaking ideas down into component parts facilitates creative reinterpretation]].
[[July 19th, 2020]]

- another great list of talks and cutting edge work relevant for [[D/Synthesis Infrastructure]] (some tech here that might be useful for powering a [[[[PTN]] - flexible compression]] pipeline), as well as potential competition / complementarity for [[D/Computational Analogy]]

    - [SciNLP: Natural Language Processing and Data Mining for Scientific Text](https://scinlp.org/)
[[My-Inbox]]

- #idea Make a [[grounded claim]] ([[[[PTN]] - flexible compression]]) embed for [[sys/RoamResearch]] (or other [[sys/Zettelkasten]] systems)

    - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FRi2NQdKRTs?alt=media&token=a9889c5a-8d0d-4efb-bb52-e0097d1cfcf9)

    - Reminds me of the prototypes in [[sys/TinderBox]] that [[Beck Tench]] uses

    - Quite feasible now with [[hiccup]]

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FPk0UH9QMlI?alt=media&token=bb0fb2a7-abae-4db9-a6f6-51e70dc16b1c)
[[January 9th, 2021]]

- Felt inspired to sketch this out tonight about the [[dialectic]] that is at the heart of the [[[[PTN]] - discourse graph]] and the idea of [[[[PTN]] - flexible compression]]

    - And I do like the phrase "[[disciplined imagination]]" as another shorthand way to talk about this [[dialectic]] [[dance between the theoretical and the evidential]], and the [[[[PTN]] - flexible compression]] required

    - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FLyzgySUC_d.png?alt=media&token=6cf535f5-8c47-44f3-9078-144aced62e14)

    - Also thinking about `question notes` as the "space" within which this dialectic can productively grow - the question notes help define the boundaries of the space, and provide a "hook" for material to be collected and to collide and grow

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2Flj-He0l83s.png?alt=media&token=0d48b6c2-ab43-4e8a-8e95-9c3fe26faad3)

        - within this space, `observation notes` can fuel [[induction]] (this is x, maybe X are Y...) and [[deduction]] for theory development (if A, then x is z, but I see that x is y, therefore...) that shows up in `synthesis note` networks

        - and `synthesis note` development can also be done to do [[abduction]], to explain observations (thinking again of what [[Charles Darwin]] did)
[[ðŸŒ² zettels]]

- [[[[PTN]] - flexible compression]] can mitigate costs of context specification for knowledge reuse

    - [[@luttersBoundaryObjectsCollaborative2007]]
[[Research proposal for P COVID-19 treatment search]]

- System: What can we (co-design) with the team to speed up the process? Where might ML, [[[[PTN]] - incremental formalization]], [[[[PTN]] - flexible compression]], etc. come in?

    - Experimenting with a collaboration system that implements [[[[PTN]] - incremental formalization]], among other things - division between domain scientists and synthesis assistants

        - Side note: new form of knowledge work? Connections to librarianship?

        - #idea What would librarianship of community [[sys/Zettelkasten]]s look like?

    - Tools for [[[[PTN]] - incremental formalization]] and [[[[PTN]] - flexible compression]] would really come in handy, integrated into the synthesis process

        - Slackbots to monitor Slack convo and extract stuff for synthesis

        - Remix of the [[[[ART]] - Knowledge Compressor]] to

            - Similar to previous idea around #idea Make a [[grounded claim]] ([[[[PTN]] - flexible compression]]) embed for [[sys/RoamResearch]] (or other [[sys/Zettelkasten]] systems)

            - Basic idea: just change the PDF reader (probably in-browser is best), and send "highlights" to a [[[[PTN]] - flexible compression]] module

    - In a [[Participatory Design]] vein, we'd want to document, in detail:

        - "Friction moments" or catalysts, (maybe also cf. [[[[CLM]] - Infrastructure is invisible until it fails]])
[[Research proposal for P COVID-19 treatment search]]

- Tools for [[[[PTN]] - incremental formalization]] and [[[[PTN]] - flexible compression]] would really come in handy, integrated into the synthesis process

    - Slackbots to monitor Slack convo and extract stuff for synthesis

    - Remix of the [[[[ART]] - Knowledge Compressor]] to

        - Similar to previous idea around #idea Make a [[grounded claim]] ([[[[PTN]] - flexible compression]]) embed for [[sys/RoamResearch]] (or other [[sys/Zettelkasten]] systems)

        - Basic idea: just change the PDF reader (probably in-browser is best), and send "highlights" to a [[[[PTN]] - flexible compression]] module
[[August 18th, 2020]]

- is the assumption that we can enumerate *some* of the various kinds of [[context]] that might turn out to be useful in particular [[synthesis]] usecases defensible / reasonable? (this is a simplifying assumption that might make our ideas around [[[[PTN]] - flexible compression]] feasible)

    - where has "defining context" been done before (or talked about / similar)?

        - shades

            - [[Metadata]]

            - analytic [[provenance]]

            - data reuse

        - objects

            - bibliographic

            - [[semantic publishing]] and [[ontologies]]

                - e.g.,

        - models

            - [[std/PROV Ontology]] for arbitrary digital objects (that are addressable)

            - [[std/sci.CRM]]

    - playing with the idea of [[context queries]] for enumerating kinds of context

    - to the extent that we want to support a shared infrastructure across a few different domains, one route is extensibility
[[January 23rd, 2021]]

- Enhanced [[[[context]]ualizability]] (e.g., [[[[PTN]] - flexible compression]]) greatly increases the "lifespan" and "fecundity" of ideas/notes, making it possible to:

    - "Join forces" with others

    - Develop insights over time

    - Synthesize ideas across projects and disciplines
[[October 16th, 2020]]

- Can then alias block refs to contextualizing bits, for a more graceful way to implement [[[[PTN]] - flexible compression]]:

    - Highest level is something like a zettel: analogous still to the [[epistemic synthesis layer]]

    - These should be grounded by / composed of / mapped to stuff from the [[epistemic foundation layer]]

        - These will be sort of super-mini abstracts, but themselves grounded in [[context snapshots]] (which might be implemented in [[sys/Hypothes.is]] annotations: for now, we implement them as context blocks in Roam)

        - We can include them more naturally / informally / narratively at first via markdown aliases as well
[[June 30th, 2022]]

- rethinking about [[[[PTN]] - flexible compression]]: experiencing this *vast* chasm between "trust me bro" and "deep dive" a la peer review

    - thinking of Idea of interaction investment from [[Andy Matuschak]]
[[July 18th, 2020]]

- Thinking again about [[context]] and [[[[PTN]] - flexible compression]].

    - [[@dourishWhatWeTalk2004]] would likely bristle at the prospect of somehow enumerating possible sets of [[context]]-relevant information bits to make available for [[[[PTN]] - flexible compression]].

        - At minimum, we should be careful not to make [[one-to-one]] mappings between some feature and whether it is or isn't [[context]]

        - One salient point to keep in mind is that [[[[CLM]] - Context is a slippery notion]].

        - This doesn't mean the task is impossible. We just shouldn't be naive about it.

    - Where might we get an enumeration of the space of possible [[context]]-relevant bits? [*]()[[[[QUE]] - What is context for the purposes of scholarly synthesis?]]

        - One source is studies of [[metaknowledge]] [[@evansMetaknowledge2011]]

        - Another clue is to think more about the **goals** of [[reuse]] for [[synthesis]], which we might phrase as questions. Each of these questions may call to mind different kinds of [[context]].

            - See list of [[context queries]]

        - Can also go bottom up from [[Query: Examples of context]]

        - Another clue is to think of "research methods" - what would convince X person that Y claim is trustworthy?

            - Ex: [[Cochrane systematic reviews]] produces standards of evidence (such as [[Risk of Bias scores]]), which rely on sets of features from papers.

            - Ex: [[@hayesKnowingDoingAction2014]] What makes for good [[m/Participatory Action Research]]? (lots more in [[Ways of Knowing in HCI]])

        - Going deeper, you can think of the consequences of [[social construction]], to get at the [[subtext]] of what is going on.

    - If a finite enumeration that covers a substantial portion of the space of [[context queries]] one might need for [[reuse]] and [[synthesis]], we can then ask: how might we obtain / elicit / surface features for these [[context]] queries?

        - info for e6ORDe7iJ can be inferred from a variety of sources

            - relationship with other claims / ideas, e.g., [[replication]] could come from links in a [[hypertext notebooks]], or citations, e.g., through [[sys/scite.ai]]

            - details of the methods could come from the manuscript itself, although important details might be missing

            - [[epistemology]] - different standards and methods for determining how we know something is true or useful will be harder to come by explicitly, but can be inferred from features such as the authorship, disciplinary orientation, or citation profile of the paper, among other features

            - authorship, cf. [[[[CL]] - People need information about authorship to reuse information]] and ((tG96I6Udn)) can be gotten directly from the paper's metadata

        - info for How might I ^^generalize^^ from these claims? For example, do these claims apply to my context? might not be directly available, but again, might be inferred from operational definitions, running examples, and so on.

            - Maybe also methods sections

            - Figures might be a particularly rich source of information about this.

        - similarly, info for How might I ^^explain^^ what is going on in this set of claims? For example, how might I explain contradictions or tensions amongst these ideas? might not be directly available, but could be inferred from details of methods and so on
[[September 22nd, 2020]]

- Good discussion with [[Xin Qian]] yesterday about the [[Question-Answering]] direction - good to keep this in mind when thinking through and prototyping ideas for [[D/Synthesis Infrastructure]], especially around [[[[PTN]] - flexible compression]] - the QA paradigm could be a powerful way to empower the reuser to navigate [[context]], without overburdening the initial capture-r

    - One pointer for her work on conversing with historical figures is [[@traumNewDimensionsTestimony2015]]

        - Although what is special about that work is less about the QA component and more about the interactivity of it and its novel application to interacting with Holocaust survivor testimonies

    - One thing that I've always struggled with: what is the relationship between QA and basic [[Information Retrieval]]?

        - But there is an IR component to QA for sure

        - From what I can tell, what's different is:

            - The stricter requirement that a **fact** is the output of the system, not simply a span of text

                - Although there appear to be simpler systems that aim at returning a span or context

                    - Even this is still a fair bit harder than calling it a day if the **document** you retrieved ended up answering the user's question

            - The complexities of requiring that the query is a natural language question (vs. advanced search syntax, or lists of keywords)

                - This makes question parsing a key subtask

                - See, e.g., this figure from [here](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.102.9112&rep=rep1&type=pdf#:~:text=Question%20Answering%20is%20a%20specialised%20form%20of%20information%20retrieval.&text=Open%2Ddomain%20question%20answering%20requires,and%20extract%20the%20correct%20answers.) on [[open-domain question-answering]]

                    - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FogV6Nm2lWV.png?alt=media&token=d3d05883-9dd8-44f7-9723-4b03250e9ee8)

    - The connection back to the synthesis project runs through the idea of [[context queries]], and probably builds on top of [[sys/RobotReviewer]]

        - There are encouraging numbers that we can do reasonable extraction of methods-like information, such as [[PICO frames]] elements: [[@wallaceExtractingPICOSentences2016]] found that in a prospective evaluation making predictions for 50 articles, and then having experts manually label the top 3 predictions from each system, the [[supervised distant supervision]] approach achieved [[measure/precision]] @3 scores of approximately .9 for all [[PICO frames]] elements
[[August 1st, 2020]]

- to me this is an #example-of methods that can provide value on the extraction side, possibly useful for [[[[PTN]] - flexible compression]]

    - is able to extract into structured fields various bits of [[context]]ual information crucial for [[synthesis]], such as experiment design, sample, and sampling method (see, e.g., [here](https://www.kaggle.com/davidmezzetti/cord-19-transmission-incubation-environment))

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FSL-yjeasg2.png?alt=media&token=b0ab4fe5-56a2-4398-bad3-cdc352225e5a)
[[April 28th, 2020]]

- Wanderings back through [[active reading]] land in thinking about [[[[PTN]] - flexible compression]]

    - Important foundational paper: [[@oharaStudentReadersUse1998]]
[[Grant proposal for Synthesis Infrastructure - NSF CHS  SOS 2020]]

- [[PDF parsing]] / [[[[PTN]] - flexible compression]] / [[[[QUE]] - What are effective ways to parse PDFs into usable structured data?]]

    - {{embed: Revisiting all the hard work that [[Matt Erhart]] did on the PDF side of things, first with [[sys/Active Science Reader]], and then with [[[[ART]] - Knowledge Compressor]]}}

    - {{embed: reminded today of [[sys/RobotReviewer]], which is evidence of the initial feasibility of obtaining hooks for [[context queries]], at least in the medical domain (see, e.g., [[@wallaceExtractingPICOSentences2016]])}}
[[February 25th, 2021]]

- Thinking through more of the infrastructure for sharing [[[[PTN]] - discourse graph]] (following from [yesterday](Feeling an [[ethnographic sneeze]] about how to jive the richly [flexibly compressed]([[[[PTN]] - flexible compression]]) of elements of the [[[[PTN]] - discourse graph]] into a shareable format that might go on something like [[sys/Ceramic]])), but also the more concrete instantiation of the various kinds of [[context]] (from below, beside, above) and [[[[PTN]] - flexible compression]] that is enabled by a block-and-page data structure

    - Here we have an `observation note`

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2F0SelwTIR2n.png?alt=media&token=8b632960-daeb-4111-a727-c8b813f858b4)

    - Let's consider how a `discourse graph` representation allows for rich contextualization of the `observation note`.

    - **Context from "below"**

        - The focal `observation note` has [[context]] from "below" through 1) a `context snippet` snapshot of the Table of results that is both indented under the observation note, and also hyperlinked into it, 2) methods details (also `observation notes`??) that live as blocks (which are themselves contextualized by `context snippets` through indentation and hyperlinking). This rich contextualizing information is available on-hover, as well as by clicking to unindent and reveal an indented block

            - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FTHTI4RtisW.png?alt=media&token=5fc50aba-5181-4173-88f9-de5429ee53c7)

        - Clicking through to a hyperlinked methods `observation note` also opens up a similar set of rich access to contextual information, through hyperlinking and indentation

            - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2Fx-H7CGmvbk.png?alt=media&token=a76d2a16-fe3c-477e-ae79-92172be3a816)

        - Importantly, the block/graph data structure also means that other contextual details from the same paper are accessible (and in principle queryable and computable for [[context queries]]) through their common parent (the paper page).

            - First, the screenshot shows how every block in the indentation "path" (every item between `>` symbols) is formally connected to the `observation note` in the underlying graph.

                - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2Fg72Hz3O9PS.png?alt=media&token=3cd2de47-385c-40a5-8b1d-aa0c08f4d8f7)

            - But every other block that is also a child of the parent page is also formally connected to the focal `observation note`, which means that details such as the procedure, experiment design, or metadata of the paper, such as authors, year, etc. are closely accessible for contextualizing the focal `observation note`.

                - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FGcwHwiAQWt.png?alt=media&token=669b3048-5443-4881-a3ba-a8985e990eb2)

            - Since every element is linkable, we can also explore details about the authors (through linked references of the author page) to help contextualize the focal `observation note`. For instance, you can ask questions like "where does this author tend to publish? What theoretical or disciplinary angles might this person be coming from?"

                - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FcoDg-EuN2I.png?alt=media&token=400b8a35-cb31-4ca5-a7cb-263d8a8f20f5)

    - **Context from above/beside**

        - The focal `observation note` also has [[context]] from "above" and "beside", through referencing in other pages or blocks. For instance, clicking on the `2` button on the right reveals two references to the focal `observation note`: 1) discussion of this result in a question note about whether/how people are efficient routes to useful cross-boundary information, and also 2) reference in a "sibling" `observation note` about a significant interaction effect between background similarity and face-to-face contact, which qualifies the original effect in an important way.

            - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FR84TnO96NK.png?alt=media&token=b33322e1-063e-4774-a53b-3f3ddf4c8122)

        - Seeing the focal `observation note` in its larger referenced/discourse context helps reveal also how having direct access to contextualizing information through hyperlinking can facilitate synthesis across `observation notes`. It might be crucial, for example, to know if there are any variations in effects by institution/prestige: is there some effect of "leeway" or resources that needs to be taken into account for face-to-face conversations to bear fruit?

            - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FkZfDRnSyoO.png?alt=media&token=fee55a9e-88df-4b6e-a9ec-323e501916c3)
[[July 29th, 2020]]

- crazy idea for [[[[PTN]] - flexible compression]] and [[context queries]] for [[D/Synthesis Infrastructure]]:

    - make assumption that there is sufficient generality in conventions in scientific writing that subclasses of [[context]] can be predicted

    - can validate?

        - any obvious red flags?

            - yes: super expensive to fine-tune, definitely can't do on a per-document basis, I don't think?

            - the NLG piece seems superfluous and adds complexity

            - super expensive to deploy

                - ideally want ot make a cheap endpoint for a zotero plugin

        - can play in citation statements to see what patterns come up?

    - basic sketch:

        - use pre-trained [[sys/SciBERT]] or similar

        - fine-tune on domain?

        - (in parallel, iteration)

            - discover useful [[context queries]] patterns (from data)

            - prompt with common [[context queries]], like "participants were...", "was measured by..."

        - fine-tune on particular document bag

            - document

            - + reviews of it (if available)

            - citation statements (if available)

        - verification / reification

        - generate latent context snippets:

            - NLG summary

            - best match snippets

    - conclusion:

        - don't pursue

        - probably a simpler "soft" classification approach is better [[idea: context predictions]]

            - maybe features:

                - genre / structural scaffolds

                - + syntactic cues

                - + some content?

                - user indication

                    - e.g., green highlight, marker (this is already common practice)

            - maybe simpler task: given highlight, classify context "type"?

        - still want ot think about a graceful interface with the soft predictions

            - more importantly, *where* and *how* this happens

                - probably gradations:

                    - for detailed read-through, can leverage markers, but annoying or them to directly mark down

                    - for skim, or strategic read, probably no markers

                - principle: make it easier to go deeper with [[idea: context predictions]]

                    - particularly over more than doc?

                    - and on a claim basis

                - principle: make it easier for others to go deeper

                    - [[idea: context traces]]

            - sketch of idea as of 10:31

                - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2Fs1oR0FXWkU.png?alt=media&token=3e7aca38-d41f-4bcc-98a8-e157e4daf0db)
[[July 18th, 2020]]

- [[@dourishWhatWeTalk2004]] would likely bristle at the prospect of somehow enumerating possible sets of [[context]]-relevant information bits to make available for [[[[PTN]] - flexible compression]].

    - At minimum, we should be careful not to make [[one-to-one]] mappings between some feature and whether it is or isn't [[context]]

    - One salient point to keep in mind is that [[[[CLM]] - Context is a slippery notion]].

    - This doesn't mean the task is impossible. We just shouldn't be naive about it.
[[June 7th, 2021]]

- This bit on the friction points of context switching reminds me very much of the idea of [[[[PTN]] - flexible compression]] and smooth gradations of access to [[context]] that [[Andy Matuschak]] [talks about](https://twitter.com/andy_matuschak/status/1266417445478100993?s=20&t=dDrOYG5H_KSaZkIgItk9EA) re: old UIs in Apple, and also to a certain degree with [[sys/Muse]]

    - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2F3MIZn1mwCQ.png?alt=media&token=be63b6e6-e17d-4f5d-b211-c843faecb2ef)

    - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FqxnFTEs9t3.png?alt=media&token=663b4455-187f-40ef-a4ec-b308a2bfab2b)
[[May 13th, 2020]]

- Thinking more about [[Question-Answering]] as an interesting paradigm for engaging with [[context]], a riff on the [[[[PTN]] - flexible compression]] angle.

    - Possibly relevant recent paper [[R: vtyurinaExploringRoleConversational2018]] (h/t [[Xin Qian]]) substantial portion (~25%) of conversational queries were implicit (e.g., repeat "that") for a recipe cooking task (from abstract)
[[February 25th, 2020]]

- Solution is [[progressive summarization]], which I guess is somewhat similar to our idea of [[[[PTN]] - flexible compression]]

    - Again, similar to our idea of [[[[CL]] - People process complex information in multiple levels and stages of processing]]
[[August 3rd, 2020]]

- random thought about why we need [[[[PTN]] - flexible compression]] for [[synthesis]] (cc [[Grant proposal for Synthesis Infrastructure - NSF CHS / SOS 2020]])

    - often the specific [[context]] details that are necessary for figuring things out [aren't obviously important details at the time you first encounter them]([[[[CLM]] - Predicting trajectories of future reuse of information objects is hard]])

        - good #example-of this is the age cutoff of ~10 yo for [[COVID-19]], crucial for answering questions about the nature of infection / transmission etc. in children - conflicting results depending on whether you draw cutoff at 10 or lump them together

            - this calls to mind the idea of [[context]] as important for [[synthesis]] as desscribed in [[@blakeCollaborativeInformationSynthesis2006]]

        - h/t this rapid review of evdience on kids and [[COVID-19]]

            - [An evidence summary of Paediatric COVID-19 literature](https://dontforgetthebubbles.com/evidence-summary-paediatric-covid-19-literature/)

            - from this tweet:

                - https://twitter.com/apsmunro/status/1290278137939591168

            - more discussion here of important [[context]]ual details

                - https://twitter.com/DiseaseEcology/status/1289298077539381248
[[January 27th, 2022]]

- reminds me very much of [[@changSupportingMobileSensemaking2016]], connecting to the ongoing idea of [[[[PTN]] - flexible compression]]

    - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FzQl7Xo1Ckc.png?alt=media&token=a8f7e809-957b-49a8-80e0-23e958f6f9a4) (p. 61)
[[February 16th, 2021]]

- illustrative: failures of [[[[PTN]] - flexible compression]] with our [[sys/NVIVO]] and [[[[ART]] - LiquidText]] users, from [[John Morabito]]'s [recent analysis](identifying information reuse events in [[WP: Context Capture Process Patterns and Tool Affordances]], specifically looking for number of clicks to context and time to find context [did first context event for p1 and watched part 1 of p2 and p5])

    - also indicates that more [[context]] is needed!
[[October 27th, 2020]]

- one question is whether the [[sys/GROBID]] parser that breaks the PDF into classifiable units retains information about the page number and bounding box information, or whether that is lossily compressed! if the latter, then no go, i think: crucial for [[[[PTN]] - flexible compression]] to always tie back to the source location

    - edit: yes it does!

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2F0qdzFzZro7.png?alt=media&token=7a5bc75f-16d7-464a-b84d-0eb64757d127) (from [here](https://hyp.is/7ygKYhieEeu691sWdQf8og/grobid.readthedocs.io/en/latest/Coordinates-in-PDF/))
[[February 24th, 2021]]

- Feeling an [[ethnographic sneeze]] about how to jive the richly [flexibly compressed]([[[[PTN]] - flexible compression]]) of elements of the [[[[PTN]] - discourse graph]] into a shareable format that might go on something like [[sys/Ceramic]]

    - To put it down into words and pictures:

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FqAyKkG4F4S.png?alt=media&token=df828843-d940-4f77-aa88-c87daf687a91)

        - Probably the thing that makes the most sense to share is `observation-notes`

            - Reuser sees the bare obs note

            - Can explore "downwards" to [recontextualize]([[recontextualization]]) in terms of production context (e.g., methods, metadata)

            - Can explore "sideways" contextualize in terms of discourse context provided by other observation notes

                - Still fuzzy what to do with the "context notes" - doesn't make sense to make hard a prior distinctions between these notes and observation notes: they're all observations!

            - Can also explore "upwards" to contextualize in terms of synthesis/question notes

        - Note: from a modeling standpoint, we have three kinds of things:

            - {{table}}

                - **question/synthesis notes**

                    - yes

                        - yes

                            - yes

                                - wiki pages

                - type

                    - URI

                        - title

                            - body

                                - current status quo analog

                - **observation notes**

                    - yes

                        - no

                            - yes

                                - comments??

                - **context snippets**

                    - not sure

                        - no

                            - yes

                                - annotations

            - Am thinking that we want our little notes about methods, etc. to be observation notes

            - Start with **past-tense verbs**, something like "reported that...", but also "sampled <who> by..." or "measured  <x>" or "manipulated <y>", or "conducted...."

                - Leave indelible marker that this is a contextualized observation - must fill out the subject, and also note that it was done at a certain time and place

                - The latter kinds are currently

                - This makes sense from a modeling standpoint: but the question arises: how do we find the observation notes that are "findings"?

                - Also not sure how to think about observations that *we* the reader make, not necessarily one that is highlighted by the author. I guess technically they did report it if we are reading it from a graph or table!

            - This structure makes it clear what is missing from public discourse, and from page-centric workflows - we get a huge gulf or gap in [[context]], between a synthesis note all the way down to a source document

        - A possible workflow for sharing:

            - We have communities oriented around questions

            - Every time a new observation note gets added to a question, people who care about that question can get notified and are able to pull that note into their own space

                - This is the first step in distributed synthesis: you can aggregate across ^^"what raw grist have other people found helpful (optionally clustered by the synthesis notes, which you can take or leave) for answering this question i also care about?"^^

            - (optionally), when the observation note gets referenced or used in some way, that is recorded on the shared ledger
[[QUE - What (existing) systems facilitate individual synthesis]]

- **CONTEXT**: [[[[CLM]] - Contextualizability is necessary for synthesis]] - [[[[PTN]] - flexible compression]]

    - First-principles/theory: [[[[CLM]] - Knowledge must be recontextualized to be usefully reused]]

        - [Evidence]([[SupportedBy]]) in scholarly domain

            - [[@blakeCollaborativeInformationSynthesis2006]]

                - some types of [[context]] information were more contextual, depending on the particular "hypothesis projection" of the review, which varied across the lifecycle of the project studied (e.g., location of medical condition, amount of exposure, confounding risk factors), while others were more constant regardless of hypothesis (e.g., study- and population-context information)

                - [[@blakeCollaborativeInformationSynthesis2006]]: director of the public health group estimated that she spent ~3 hrs per article to extract [[context]] information required  for a particular [[systematic review]]

            - [[@morabitoManagingContextScholarly2021]] context

    - [[scholarly primitives]] work that includes [[[[CLM]] - Scholars constantly need to reread during a literature review]]

        - [[@oharaStudentReadersUse1998]] re-reading
