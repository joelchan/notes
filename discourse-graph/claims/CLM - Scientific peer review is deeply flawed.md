---
title: [[CLM]] - Scientific peer review is deeply flawed
url: https://roamresearch.com/#/app/megacoglab/page/4mnOmoUjr
author: Joel Chan
date: Tue Jun 09 2020 17:01:51 GMT-0400 (Eastern Daylight Time)
---

- #[[üå≤ zettels]]

    - Tags: #[[Z]]

    - Description

        - For example: Good article on problems with (reject-if-not-SOTA) [[peer review]] in NLP: https://hackingsemantics.xyz/2020/reviewing-models/

        - this made the rounds on twitter: "In a controlled experiment with two disjoint program committees, the ACM International Conference on¬†Web Search and Data Mining (WSDM'17) found that reviewers with author information were 1.76x more¬†likely to recommend acceptance of papers from famous authors, and 1.67x more likely to recommend¬†acceptance of papers from top institutions.‚Äù (from¬†[here](https://cacm.acm.org/magazines/2018/6/228027-effectiveness-of-anonymization-in-double-blind-review/fulltext#R6), referencing¬†[this study](https://arxiv.org/pdf/1702.00502.pdf); famous precursor to this is the peters and ceci study that showed many papers from prestigious authors/institutions didn‚Äôt make it through the next time; commentary on that¬†[here](https://thewinnower.com/discussions/7-_the-_peters-_ceci-_study-_of-_journal-_publications

        - Although #[[‚ùóbeware]]: our level of knowledge is far thinner than we would like, as #[[@tennantLimitationsOurUnderstanding2020]] argue in a review of the literature.

###### Discourse Context

- **Informed By::** [[@tennantLimitationsOurUnderstanding2020]]

###### References

[[June 14th, 2020]]

- Some studies in here for [[[[CLM]] - Prestige substantially controls how scientific ideas spread]] - via the [[peer review]] route (so also [[[[CLM]] - Scientific peer review is deeply flawed]])

    - [One reason peer review is broken: it‚Äôs biased in favor of prestigious authors](https://www.vox.com/science-and-health/2016/11/29/13770988/peer-review-bias-authors)

        - #quotes

            - - There‚Äôs evidence that peer reviewers are more lenient toward prestigious researchers
[[March 1st, 2021]]

- cc [[[[CLM]] - Scientific peer review is deeply flawed]]

    - https://twitter.com/mcmullarkey/status/1366091614691721216
[[Week of February 14th, 2022]]

- bunch of papers that can inform [[[[CLM]] - Scientific peer review is deeply flawed]]

    - Off to a Patchy Start: Milestones in Journal Peer Review Research, Part 1 (1945‚Äì1989) - Absolutely Maybe: https://absolutelymaybe.plos.org/2019/04/30/off-to-a-patchy-start-milestones-in-journal-peer-review-research-part-1-1945-1989/

    - Trials At Last & Even More Questions: Milestones in Journal Peer Review Research, Part 2 (1990‚Äì2018) - Absolutely Maybe: https://absolutelymaybe.plos.org/2019/04/30/trials-at-last-even-more-questions-milestones-in-journal-peer-review-research-part-2-1990-2018/

    - 5 Things We Learned About Peer Review in 2019 - Absolutely Maybe: https://absolutelymaybe.plos.org/2019/12/31/5-things-we-learned-about-peer-review-in-2019/

    - 5 Things We Learned About Peer Review in 2020 - Absolutely Maybe: https://absolutelymaybe.plos.org/2021/02/02/5-things-we-learned-about-peer-review-in-2020/

    - 5 Things We Learned About Journal Peer Review in 2021 - Absolutely Maybe: https://absolutelymaybe.plos.org/2021/12/31/5-things-we-learned-about-journal-peer-review-in-2021/
[[Week of June 13th, 2022]]

- cc [[[[CLM]] - Scientific peer review is deeply flawed]]

    - Does double‚Äêblind peer review reduce bias? Evidence from a top computer science conference - Sun - 2022 - Journal of the Association for Information Science and Technology - Wiley Online Library https://asistdl.onlinelibrary.wiley.com/doi/10.1002/asi.24582

    - Science Fictions: How Fraud, Bias, Negligence, and Hype Undermine the Search for Truth Illustrated, Ritchie, Stuart - Amazon.com https://www.amazon.com/dp/B07WZ7TRC4/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1

    - Peer review: a flawed process at the heart of science and journals - PMC https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1420798/

    - Peer-review crisis creates problems for journals and scholars https://www.insidehighered.com/news/2022/06/13/peer-review-crisis-creates-problems-journals-and-scholars

    - Let's stop pretending peer review works - Vox https://www.vox.com/2015/12/7/9865086/peer-review-science-problems

    - Peer Review in Science: the pains and problemsÔøº - Science in the News https://sitn.hms.harvard.edu/flash/2022/peer-review-in-science-the-pains-and-problems/

    - Peer-Reviewed Scientific Journals Don't Really Do Their Job | WIRED https://www.wired.com/story/peer-reviewed-scientific-journals-dont-really-do-their-job/

    - Science Integrity Digest ‚Äì A blog about science integrity, by Elisabeth Bik, for Harbers-Bik LLC. Support my work at Patreon.com/elisabethbik https://scienceintegritydigest.com/

    - Contest models highlight inherent inefficiencies of scientific funding competitions | PLOS Biology https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000065

    - Arbitrariness in the peer review process - [scite report] https://scite.ai/reports/arbitrariness-in-the-peer-review-EDxONw1?page=1

    - Scientometrics of peer review | SpringerLink https://link.springer.com/article/10.1007/s11192-017-2518-4

    - lots of hoo-ha about the peer review process at [[NeurIPS]] imploding this year due to terrible automated matching of ACs to submissions in response to increasingly unsustainable imbalance between submissions and available reviewers

        - Zachary Lipton on Twitter: "The NeurIPS AC paper matching was so devastatingly bad this year that it puts the conference at risk. We‚Äôd be better off pumping the breaks & redoing assignments, even if it cost 2 weeks versus going ahead like this. I don‚Äôt know a single AC less than crestfallen by their pile." / Twitter

            - tweet

                - https://twitter.com/zacharylipton/status/1536799053790445569

        - Kyunghyun Cho on Twitter: "@zacharylipton @NeurIPSConf bidding or not, it's quite inevitable to see some mismatches between assignments and area chairs/reviewers's expertise/interest, as we can't really guarantee nor encourage topic distributions between submissions and committee's expertise/interest to match perfectly. (cont.)" / Twitter

            - tweet

                - https://twitter.com/kchonyc/status/1537116208843083779

        - Tiago Peixoto on Twitter: "I can't help but marvel at the gigantic irony that the leading ML conference cannot solve a relatively simple reviewer matching problem." / Twitter

            - tweet

                - https://twitter.com/tiagopeixoto/status/1537072811063246849

        - Gautam Kamath on Twitter: "I slept on it, and for the time being, I'll be declining future AC invitations where no bidding is allowed. AC jobs are already dangerously close to being yet another administrative task that academics are overwhelmed with. This policy removes the ambiguity." / Twitter

            - tweet

                - https://twitter.com/thegautamkamath/status/1537067809393582085
[[June 9th, 2020]]

- Heartbreaking #example-of how [[[[CLM]] - Scientific peer review is deeply flawed]], failed to catch substantial collusion amongst groups of authors and editors, resulted in a student's suicide

    - https://medium.com/@tnvijayk/potential-organized-fraud-in-acm-ieee-computer-architecture-conferences-ccd61169370d
[[June 14th, 2020]]

- This paper documents it: https://www.nature.com/news/scientific-publishing-the-inside-track-1.15424 - nuanced by the fact that most people don't use it, and it's used heavily by only a small number of people. But importantly, the mechanism was used and justified because there was a sense that [[[[CLM]] - Scientific peer review is deeply flawed]]

    - [Scientific publishing: The inside track](https://www.nature.com/news/scientific-publishing-the-inside-track-1.15424)

        - #quotes

            - These scientists say that the main motivator for using the contributed track is an intense frustration with the peer-review process at other high-profile journals, which they argue has become excessive and laborious

            - Complaints about nitpicking reviews at Nature and Science go hand-in-hand with the charge that the editors at these journals are in thrall to trendy areas of research. ‚ÄúVery often what seems to be fashionable is not very good science,‚Äù says Croce.

    - See also: https://scholarlykitchen.sspnet.org/2016/01/14/pnas-tighter-editorial-policy-improves-nas-papers/

        - Original source was this Twitter post:

            - https://twitter.com/nataliexdean/status/1271777475798892544/photo/1
[[June 14th, 2020]]

- More on [[[[CLM]] - Scientific peer review is deeply flawed]] -

    - [‚ÄúMerit‚Äù and the NIH disparity of grant award to Black PIs](https://drugmonkey.scientopia.org/2020/06/10/merit-and-the-nih-disparity-of-grant-award-to-black-pis/)

        - #quotes

            - some apps from African-American PIs were not being funded at a given near-miss score while some apps from white PIs were being funded at worse scores

            - Discretionary funding decisions, i.e. outside of percentile ranks where nearly every application is funded, do in fact contribute substantially to the disparity.

            - and correcting this to give Black PIs a fair hit rate, by selecting applications of HIGHER MERIT, would cause an entirely imperceptible change in the chances for white PIs

    - includes discussion of this recent-ish paper that finds Black scientists are more likely to propose studying solutions at a community / race level, and those topics are less likely to get funded at [[NIH]]: #[[R: hoppeTopicChoiceContributes2019]]
[[June 14th, 2021]]

- vivid contrived #example-of [[[[CLM]] - Scientific peer review is deeply flawed]]

    - see also [[@trafimowWhatIfSocial2009]]
[[August 19th, 2021]]

- [[[[CLM]] - Scientific peer review is deeply flawed]]

    - Low agreement among reviewers evaluating the same NIH grant applications - [[[scite report]]]: https://scite.ai/reports/low-agreement-among-reviewers-evaluating-9OlQQYA?mentioning=false&page=1&utm_campaign=plugin&utm_medium=plugin&utm_source=generic

    - Arbitrariness in the peer review process - [[[scite report]]]: https://scite.ai/reports/arbitrariness-in-the-peer-review-EDxONw1 [[@brezisArbitrarinessPeerReview2020]]
[[June 20th, 2022]]

- [[[[CLM]] - Scientific peer review is deeply flawed]]

    - original [[NeurIPS]] experiment is in [[@ragonePeerReviewComputer2013]]

        - later [[@brezisArbitrarinessPeerReview2020]] create a model and replicate the NeurIPS results with their model
[[CLM - Prestige substantially controls how scientific ideas spread]]

- As a specific manifestation of [[[[CLM]] - Scientific peer review is deeply flawed]]

    - this made the rounds on twitter: "In a controlled experiment with two disjoint program committees, the ACM International Conference on¬†Web Search and Data Mining (WSDM'17) found that reviewers with author information were 1.76x more¬†likely to recommend acceptance of papers from famous authors, and 1.67x more likely to recommend¬†acceptance of papers from top institutions.‚Äù (from¬†[here](https://cacm.acm.org/magazines/2018/6/228027-effectiveness-of-anonymization-in-double-blind-review/fulltext#R6), referencing¬†[this study](https://arxiv.org/pdf/1702.00502.pdf); famous precursor to this is the peters and ceci study that showed many papers from prestigious authors/institutions didn‚Äôt make it through the next time; commentary on that¬†[here](https://thewinnower.com/discussions/7-_the-_peters-_ceci-_study-_of-_journal-_publications))
[[June 7th, 2021]]

- cc [[[[CLM]] - Scientific peer review is deeply flawed]]

    - see also: /docs/statistics/peerreview/ Directory Listing ¬∑ Gwern.net: https://www.gwern.net/docs/statistics/peerreview/index
[[Discussion with Protocol Labs Metaresearch Journal Club, about @strasserBusinessExtractingKnowledge2021]]

- most papers are terrible because [[[[CLM]] - Prevailing incentives in academia are bad for science]] (e.g., [[[[CLM]] - Scientific peer review is deeply flawed]], [[[[CLM]] - Citation practices in science are far from optimal]])

    - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FhaDF07AxE4.png?alt=media&token=2698866b-eccd-4f73-b1a9-23df2d8425fc)

    - counterpoint: lagging indicators, [[[[CLM]] - bibliometric measures are biased against novel breakthrough research - [[@wangBiasNoveltyScience2017]]]] what do we lose by continuing to rely on this "great man" heuristic? and increasingly so as the number of papers grows?

        - [[[[EVD]] - highly novel papers were more likely to be in the top 1% of citations in the long run, but not in the short run, and particularly in other fields - [[@wangBiasNoveltyScience2017]]]]

        - see also On (Not) Reading Papers - LessWrong: https://www.lesswrong.com/posts/72QA8qk9g6wZNDWeS/on-not-reading-papers
