---
title: [[CLM]] - Compression and contextualizability are in tension
url: https://roamresearch.com/#/app/megacoglab/page/eiCoI_04x
author: Joel Chan
date: Wed Apr 20 2022 11:27:12 GMT-0400 (Eastern Daylight Time)
---



###### Discourse Context



###### References

[[January 8th, 2021]]

- we discussed some baseline designs to compare against [[[[PTN]] - discourse graph]] for interacting with heterogenous evidence collections (again, I think core problem is [tradeoff between context and compression]([[[[CLM]] - Compression and contextualizability are in tension]]))

    - high degree of [[compression]] that is lossy:

    - [[What Works ClearingHouse]] quant-focused, similar to [[Cochrane systematic reviews]] in terms of focusing on "scoring" quality of evidence: https://ies.ed.gov/ncee/wwc/Intervention/752

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2F0CBlfS_Vhk.png?alt=media&token=d159adc1-46a9-4872-a3ed-1ad3e20c77a5)

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2F26G7d_9_oJ.png?alt=media&token=f7aa909b-adc4-45f3-8877-dd08539cc84f)

        - Not totally lossy compression, since there is a link to an intervention report, which discusses the rationale behind (cf. [[outline/2020-10 - supporting explicit reasoning over evidence context for claims (ASIST workshop)]]): https://ies.ed.gov/ncee/wwc/Docs/InterventionReports/wwc_firststep_030612.pdf

    - [[org/LearnLab]] maintains a [[sys/Wiki]] focused on ideas around robust learning: https://learnlab.org/research/wiki/Main_Page - here the emphasis is less on evidence contention, and more on theoretical [[synthesis]] - references are cited in the usual way, so compression is quite lossy, although context is high in the sense of significance (since it's a kind of [[hypertext notebooks]])

    - [[Erik Harpstead]] made a "card deck" of learning science principles that is beautiful and very usable, but totally lossy in terms of [[compression]]

        - https://eharpste.github.io/interactive-principles/#/

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FMdsFCEzKk_.png?alt=media&token=80484565-4b04-48ef-9608-7e01cc6b5a30)

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FvitSRql8hN.png?alt=media&token=42f31e77-c12f-432c-bfd9-0b2a9bd21313)

        - since compression is totally lossy, you basically have to trust the source completely, both in terms of authorship, and timeliness
