---
title: [[CLM]] - Compressing complex ideas into more manageable chunks facilitates more complex thought
url: https://roamresearch.com/#/app/megacoglab/page/0gb6dThPL
author: Joel Chan
date: Thu May 14 2020 16:58:56 GMT-0400 (Eastern Daylight Time)
---

- #[[üå≤ zettels]]

    - Tags: #Atomicity #synthesis #[[working memory]]

    - Description

        - [[@mccrickardMakingClaimsKnowledge2012]] talks about the idea of being able to rapidly explore connections between many ideas as an important precondition for creatively reusing prior knowledge. This gets hard when the idea units are too large to comprehend quickly ([linEmployingPatternsLayers2008](some users struggled to understand large design patterns #[[üìù lit-notes]] #Atomicity #[[context]]ualizability (p. 1321)))

        - In studies of human [[expertise]], we find that [[Chunking]] in memory is a major enabler of expert thinking [[@chaseMindEyeChess1973]]: experts are able to think "bigger", more complex thoughts by compressing complex ideas into memory chunks to overcome the limitations of working memory (+/- 4 [[@cowanMagicalNumberShortterm2000]], which we previously thought was 7)

        - Of course, a much more powerful way to extend thinking space is to leverage [[distributed cognition]] and [[externalization]]. But even then you still run into the limitations of your visual field and the physical area.

        - One metaphor for this is the idea of [[C: Compression]]

        - This "shrinking" is often accomplished by [[abstraction]]. While powerful, abstraction can impede synthesis if [[context]] isn't easy to recover (i.e., if the compression is "lossy"), because [[[[CL]] - Compression and contextualizability are in tension]], and [[[[CLM]] - Contextualizability is necessary for synthesis]]

    - R-Sources

###### Discourse Context

- **Informed By::** [[@mccrickardMakingClaimsKnowledge2012]]
- **Informed By::** [[@cowanMagicalNumberShortterm2000]]
- **Informed By::** [[@chaseMindEyeChess1973]]
