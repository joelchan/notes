---
title: [[CLM]] - Error detection work in science is systematically undervalued
url: https://roamresearch.com/#/app/megacoglab/page/9KYfK_ETt
author: Joel Chan
date: Sun Jun 21 2020 23:42:06 GMT-0400 (Eastern Daylight Time)
---

- #[[ðŸŒ² zettels]] #[[Z]]

    - Tags: #[[D/Synthesis Infrastructure]] #[[V: Open and Sustainable Innovation Systems]]

    - Description

        - [[@heathersQuit2020]] details some vivid personal examples from his experience as someone doing error detection work, but ultimately leaving academia to continue that work because he wasn't able to sustain it within the academic incentive structures

        - This is an #example-of how [[[[CLM]] - Prevailing incentives in academia are bad for science]]

    - R-Sources

###### Discourse Context

- **Informed By::** [[@heathersQuit2020]]

###### References

[[June 21st, 2020]]

- Lots of concrete stuff in here relevant for [[[[CLM]] - Prevailing incentives in academia are bad for science]], specifically about the fact that error detection work isn't rewarded. The generalization of this is that [[[[CLM]] - Error detection work in science is systematically undervalued]]

    - Related piece by [[Josh Nicholson]] (who started [[sys/scite.ai]]): https://www.statnews.com/2015/12/10/phd-academic-culture-must-change/

    - And more by [[Simon DeDeo]] analyzing how science can be a "game", which helps produce behaviors such as failing to prosecute [[Questionable Research Practices]] and barriers to open science or [[semantic publishing]]? [[@dedeoWhenScienceGame2020]]

        - Reminds me very much of stuff that [[David Chapman]] talks about with [[@chapmanUpgradeYourCargo2016]] on [[Cargo Cult Science]]
