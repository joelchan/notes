---
title: [[CLM]] - Prevailing incentives in academia are bad for science
url: https://roamresearch.com/#/app/megacoglab/page/Di6-UFQ5t
author: Joel Chan
date: Sun Mar 01 2020 21:53:43 GMT-0500 (Eastern Standard Time)
---

- #[[ðŸŒ² zettels]]

    - Tags: #[[D/Synthesis Infrastructure]] #[[V: Open and Sustainable Innovation Systems]]

    - Description:

        - [[[[CLM]] - Prestige substantially controls how scientific ideas spread]]

        - Current [[incentives]] bias favor [[short-termism]]

            - For example, [[[[CL]] - Scientists prefer to pursue safer incremental advances rather than risky breakthroughs]]

            - This is bad for science because [[[[CLM]] - True creative breakthroughs often take a long time to develop]]

        - [[[[CLM]] - Scientific peer review is deeply flawed]]

        - [[[[CLM]] - Citation practices in science are far from optimal]]

        - [[[[CLM]] - Error detection work in science is systematically undervalued]]

        - [[[[CLM]] - bibliometric measures are biased against novel breakthrough research - [[@wangBiasNoveltyScience2017]]]]

    - R-Sources:

        - [[@heesen2018reward]]

            - #Claim Imperfections in [[peer review]] and the way credit is awarded systematically favor lower levels of reproducibility

        - [[@smaldinoNaturalSelectionBad2016]]

            - In a similar fashion to what is seen in empirical observations of scientific practice, selecting for high output in [the model](((DRG86XRFt))) led to the proliferation of poorer methods, such as low statistical power, and increasingly high false discovery rates

        - [[@nosekScientificUtopiaII2012]]

        - [[@fortnowViewpointTimeComputer2009]]

            - Discusses (mostly from personal experience) the issues with a conference-driven publication culture, including deadline-driven, [[least-publishable unit]] stuff, possibly [[short-termism]] too

        - [[@bengioTimeRethinkPublication2020]]

        - [[@johnMeasuringPrevalenceQuestionable2012]]

            - Approximately 50% of psychologists have engaged in [[Questionable Research Practices]] (short of falsifying data) at least once (p. 527)

                - ((7ia6XJRBw))

        - [[@everettTragedyAcademicCommons2015]]

        - [[@britzAIResearchReplicability2020]]

            - [[SOTA]] from old models are actually not really improved upon that much

        - [[@dedeoWhenScienceGame2020]]

            - science can be a "game", which helps produce behaviors such as failing to prosecute [[Questionable Research Practices]] and barriers to open science or [[semantic publishing]]

###### Discourse Context

- **Informed By::** [[@bengioTimeRethinkPublication2020]]
- **Informed By::** [[@dedeoWhenScienceGame2020]]
- **Informed By::** [[@heesen2018reward]]
- **Informed By::** [[@britzAIResearchReplicability2020]]
- **Informed By::** [[@wangBiasNoveltyScience2017]]
- **Informed By::** [[@fortnowViewpointTimeComputer2009]]
- **Informed By::** [[@johnMeasuringPrevalenceQuestionable2012]]
- **Informed By::** [[@everettTragedyAcademicCommons2015]]
- **Informed By::** [[@smaldinoNaturalSelectionBad2016]]
- **Informed By::** [[@nosekScientificUtopiaII2012]]
