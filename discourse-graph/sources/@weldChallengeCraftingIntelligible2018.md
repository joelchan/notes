---
title: @weldChallengeCraftingIntelligible2018
url: https://roamresearch.com/#/app/megacoglab/page/8xwORDiDU
author: Joel Chan
date: Tue Oct 20 2020 15:40:07 GMT-0400 (Eastern Daylight Time)
---

- #[[references]]

    - Title: The Challenge of Crafting Intelligible Intelligence

    - Meta:

        - Authored by:: [[Daniel S. Weld]] [[Gagan Bansal]]

        - Year: [[2018]]

        - Zotero link: [Zotero Link](zotero://select/items/1_64XN3NDX)

###### Discourse Context



###### References

[[October 20th, 2020]]

- From [[@weldChallengeCraftingIntelligible2018]]: a frame of [[explainable AI]] and interpretability focuses on explicit, formal, and succinct *explanations*, much like theories, often in terms of a relatively small number of features.

    - But as they point out, adopting explanation as a hard constraint might be a severe limit on performance: the world is not kind, and often the sort of intelligence needed to solve problems in that world may be uninterpretable in this narrow sense, perhaps not unlike humans!

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2F7nWxy3GZpQ.png?alt=media&token=4d9bab07-d367-43b6-9e04-39dcf3be96bb)

        - Possibly related: [[@hongHumanFactorsModel2020]]

        - [[@lillicrapWhatDoesIt2019]] makes a version of this point, arguing that there is a limit to how much we can [compress]([[compression]]) an intelligent system of meaningful complexity, not unlike the human brain!

            - striking #example-of this: networks that do well on [[dataset/ImageNet]] cannot really be compressed to fewer than 100k parameters

                - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2Fl79QNgnnC_.png?alt=media&token=c47295a7-1382-4fbd-8101-21b4904ba60b)
