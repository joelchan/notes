---
title: @reynoldsPromptProgrammingLarge2021a
url: https://roamresearch.com/#/app/megacoglab/page/Wo0jZm95X
author: Joel Chan
date: Mon Nov 08 2021 10:06:35 GMT-0500 (Eastern Standard Time)
---

- Title:: Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm
- Author(s):: [[Laria Reynolds]], [[Kyle McDonell]]
- Abstract:: Prevailing methods for mapping large generative language models to supervised tasks may fail to sufficiently probe modelsâ€™ novel capabilities. Using GPT-3 as a case study, we show that 0-shot prompts can significantly outperform few-shot prompts. We suggest that the function of few-shot examples in these cases is better described as locating an already learned task rather than meta-learning. This analysis motivates rethinking the role of prompts in controlling and evaluating powerful language models. We discuss methods of prompt programming, emphasizing the usefulness of considering prompts through the lens of natural language. We explore techniques for exploiting the capacity of narratives and cultural anchors to encode nuanced intentions and techniques for encouraging deconstruction of a problem into components before producing a verdict. Informed by this more encompassing theory of prompt programming, we also introduce the idea of a metaprompt that seeds the model to generate its own natural language prompts for a range of tasks. Finally, we discuss how these more general methods of interacting with language models can be incorporated into existing and future benchmarks and practical applications.
- Type:: [[Conference paper]]
- Publication::
- URL : https://dl.acm.org/doi/10.1145/3411763.3451760
- Date Added:: [[November 8th, 2021]]
- Zotero links:: [Local library](zotero://select/groups/2451508/items/WX8NVBE4), [Local library](https://www.zotero.org/groups/2451508/items/WX8NVBE4)
- PDF links : [Reynolds and McDonell - 2021 - Prompt Programming for Large Language Models Beyo.pdf](zotero://open-pdf/groups/2451508/items/GY9HVAES)
- supersedes [[@reynoldsPromptProgrammingLarge2021]]
- has already been cited 18 times on GS!

    - https://scholar.google.com/scholar?cites=14522716310248947104&as_sdt=20000005&sciodt=0,21&hl=en

###### Discourse Context

- **Informs::** [[QUE - What do we know about transformer language models' natural language generation capabilities]]
