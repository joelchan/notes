---
title: @woodruffQualitativeExplorationPerceptions2018a
url: https://roamresearch.com/#/app/megacoglab/page/ASswHed5w
author: Joel Chan
date: Fri May 14 2021 11:27:45 GMT-0400 (Eastern Daylight Time)
---



###### Discourse Context

- **Informs::** [[QUE - What tension points exist between the goals of diversity and depth of user participation in participatory design]]

###### References

[[QUE - What tension points exist between the goals of diversity and depth of user participation in participatory design]]

- [[@woodruffQualitativeExplorationPerceptions2018a]]

    - #[[references]]

        - Title: A qualitative exploration of perceptions of algorithmic fairness

        - Meta:

            - Authored by:: [[Allison Woodruff]] [[Sarah E. Fox]] [[Steven Rousso-Schindler]] [[Jeffrey Warshaw]]

            - Year: [[2018]]

            - Publication: undefined

            - Zotero link: [Zotero Link](zotero://select/items/7_ANXICW9G)

            - URL: [Woodruff et al. (2018). A qualitative exploration of perceptions of algorithmic fairness. undefined](https://doi.org/10.1145/3173574.3174230)

        - Content

            - Abstract

                - Algorithmic systems increasingly shape information people are exposed to as well as influence decisions about employment, finances, and other opportunities. In some cases, algorithmic systems may be more or less favorable to certain groups or individuals, sparking substantial discussion of algorithmic fairness in public policy circles, academia, and the press. We broaden this discussion by exploring how members of potentially affected communities feel about algorithmic fairness. We conducted workshops and interviews with 44 participants from several populations traditionally marginalized by categories of race or class in the United States. While the concept of algorithmic fairness was largely unfamiliar, learning about algorithmic (un)fairness elicited negative feelings that connect to current national discussions about racial injustice and economic inequality. In addition to their concerns about potential harms to themselves and society, participants also indicated that algorithmic fairness (or lack thereof) could substantially affect their trust in a company or product.
