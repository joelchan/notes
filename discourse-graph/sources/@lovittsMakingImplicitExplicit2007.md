---
title: @lovittsMakingImplicitExplicit2007
url: https://roamresearch.com/#/app/megacoglab/page/UsgZoMC8k
author: Joel Chan
date: Mon Feb 17 2020 09:34:11 GMT-0500 (Eastern Standard Time)
---

- Title:: Making the Implicit Explicit: Creating Performance Expectations for the Dissertation
- Author(s):: [[Barbara E. Lovitts]]
- Abstract:: Despite their and other stakeholdersâ€™ consistent demand for excellence, doctoral programs have rarely, if ever, been assessed in terms of the quality of the dissertations departments produce. Yet dissertations provide the most powerful, objective measure of the success of a departmentâ€™s doctoral program. Indeed, assessment, when done properly, can help departments achieve excellence by providing insight into a programâ€™s strengths and weaknesses.This book and the groundbreaking study on which it is based is about making explicit to doctoral students the tacit â€œrulesâ€ for the assessment of the final of all final educational productsâ€•the dissertation. The purpose of defining performance expectations is to make them more transparent to graduate students while they are in the researching and writing phases, and thus to help them achieve to higher levels of accomplishment. Lovitts proposes the use of rubrics to clarify performance expectationsâ€“not to rate dissertations or individual components of dissertations to provide a summary score, but to facilitate formative assessment to support, not substitute for, the advising process. She provides the results of a study in which over 270 faculty from ten major disciplinesâ€•spanning the sciences, social sciences, and humanitiesâ€•were asked to make explicit their implicit standards or criteria for evaluating dissertations. The book concludes with a summary of the practical and research implications for different stakeholders: faculty, departments, universities, disciplinary associations, accrediting organizations, and doctoral students themselves.The methods described can easily be adapted for the formative assessment of capstone courses, senior and masterâ€™s theses, comprehensive exams, papers, and journal articles.
- Type:: [[Book]]
- Publication::
- URL : https://www.amazon.com/Making-Implicit-Explicit-Expectations-Dissertation/dp/1579221815
- Date Added:: [[July 31st, 2021]]
- Zotero links:: [Local library](zotero://select/groups/2451508/items/BGB32NCK), [Local library](https://www.zotero.org/groups/2451508/items/BGB32NCK)
- #[[references]]

    - Title: Making the Implicit Explicit: Creating Performance Expectations for the Dissertation

    - Meta:

        - Authored by:: [[Barbara E. Lovitts]]

        - Year: [[2007]]

        - Publication: undefined

        - Zotero link: [Zotero Link](zotero://select/items/1_K4PLWHG8)

        - URL: [Lovitts (2007). Making the Implicit Explicit: Creating Performance Expectations for the Dissertation.](https://www.amazon.com/Making-Implicit-Explicit-Expectations-Dissertation/dp/1579221815)

    - Content

        - Abstract

            - Despite their and other stakeholdersâ€™ consistent demand for excellence, doctoral programs have rarely, if ever, been assessed in terms of the quality of the dissertations departments produce. Yet dissertations provide the most powerful, objective measure of the success of a departmentâ€™s doctoral program. Indeed, assessment, when done properly, can help departments achieve excellence by providing insight into a programâ€™s strengths and weaknesses.This book and the groundbreaking study on which it is based is about making explicit to doctoral students the tacit â€œrulesâ€ for the assessment of the final of all final educational productsâ€•the dissertation. The purpose of defining performance expectations is to make them more transparent to graduate students while they are in the researching and writing phases, and thus to help them achieve to higher levels of accomplishment. Lovitts proposes the use of rubrics to clarify performance expectationsâ€“not to rate dissertations or individual components of dissertations to provide a summary score, but to facilitate formative assessment to support, not substitute for, the advising process. She provides the results of a study in which over 270 faculty from ten major disciplinesâ€•spanning the sciences, social sciences, and humanitiesâ€•were asked to make explicit their implicit standards or criteria for evaluating dissertations. The book concludes with a summary of the practical and research implications for different stakeholders: faculty, departments, universities, disciplinary associations, accrediting organizations, and doctoral students themselves.The methods described can easily be adapted for the formative assessment of capstone courses, senior and masterâ€™s theses, comprehensive exams, papers, and journal articles.
- #references

    - Title: Making the Implicit Explicit: Creating Performance Expectations for the Dissertation

    - Meta

        - Tags: #ref/Book #[[D/Synthesis Infrastructure]] #[[P/Teach INST 888]]

        - Authored by:: [[Barbara E. Lovitts]]

        - Year: [[2007]]

        - URL: https://www.amazon.com/Making-Implicit-Explicit-Expectations-Dissertation/dp/1579221815

    - #lit-context

        - One of only two exemplary empirically grounded studies of doctoral students' success/challenges at [[synthesis]], operating at the artifact level (there are others that examine in interviews/surveys); the other is [[@holbrookInvestigatingPhDThesis2004]]

        - #participants were [[N=]] 276 "PhD-productive" (advising on average 10s of dissertations, and participating in more) faculty across [[N=]] 74 departments in [[N=]] 10 disciplines spanning the sciences, social sciences, and humanities, across [[N=]] 9 different universities

        - #method was #m/Qualitative analysis of ~90-minute #[[m/Semi-structured interviews]] with #[[m/Focus Group]]s

        - Their #method: analyzing  comments for a large number of actual dissertations across a wide range of disciplines that span the humanities, social sciences, and traditional STEM, including biology, physics, ECE, math, economics, psych, sociology, english, history, and philosophy

            - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FRu2_E_qw_N?alt=media&token=53a8fa79-3acc-4eb0-bb92-845a1b86d0e6)

    - #[[ğŸ“ lit-notes]]

        - [[[[EVD]] - Doctoral examiners reported that many acceptable or even "very good" dissertations across a range of disciplines fell well short of implicit and explicit criteria for effective synthesis in their literature reviews - [[@lovittsMakingImplicitExplicit2007]]]]

            - Ineffective [[synthesis]] is not a reason to fail a dissertation! Qualities associated with literature reviews in "acceptable" (or even "very good")  dissertations fall well short of implicit and explicit criteria for effective synthesis (e.g., [[@strikeTypesSynthesisTheir1983]], [[@booteScholarsResearchersCentrality2005]]

###### Discourse Context

- **Informs::** [[CLM - Doctoral students struggle to effectively synthesize literature]]
- **Informs::** [[QUE - How might we conceptualize and measure synthesis quality]]
- **SourceFor::** [[EVD - Doctoral examiners reported that many acceptable or even very good dissertations across a ran...iteria for effective synthesis in their literature reviews - @lovittsMakingImplicitExplicit2007]]

###### References

[[CLM - Doctoral students struggle to effectively synthesize literature]]

- #[[@lovittsMakingImplicitExplicit2007]]

    - Ineffective [[synthesis]] is not a reason to fail a dissertation! Qualities associated with literature reviews in "acceptable" (or even "very good")  dissertations fall well short of implicit and explicit criteria for effective synthesis (e.g., [[@strikeTypesSynthesisTheir1983]], [[@booteScholarsResearchersCentrality2005]]
[[June 29th, 2021]]

- [[@lovittsMakingImplicitExplicit2007]] has rubrics from a bunch of fields

    - intuition quote:

        - > Students who write acceptable literature reviews often take the literature they have read at face value and do not (or cannot) discriminate between good papers and bad ones. Their literature reviews are descriptive summaries, â€œso-and-so and so-and-so said,â€, that make obvious points. Similarly, unacceptable literature reviews lack an organizing intelligence. (p. 45)
[[@lovittsMakingImplicitExplicit2007]]

- [[[[EVD]] - Doctoral examiners reported that many acceptable or even "very good" dissertations across a range of disciplines fell well short of implicit and explicit criteria for effective synthesis in their literature reviews - [[@lovittsMakingImplicitExplicit2007]]]]

    - Ineffective [[synthesis]] is not a reason to fail a dissertation! Qualities associated with literature reviews in "acceptable" (or even "very good")  dissertations fall well short of implicit and explicit criteria for effective synthesis (e.g., [[@strikeTypesSynthesisTheir1983]], [[@booteScholarsResearchersCentrality2005]]
[[Teach INST 802 Week 8 (Mar 14) - Process - Synthesis 1]]

- From [[@lovittsMakingImplicitExplicit2007]]

    - > Students who write acceptable literature reviews often take the literature they have read at face value and do not (or cannot) discriminate between good papers and bad ones. Their literature reviews are descriptive summaries, â€œso-and-so and so-and-so said,â€, that make obvious points. Similarly, unacceptable literature reviews lack an organizing intelligence. (p. 45)
