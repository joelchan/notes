---
title: @ackermanSharingKnowledgeExpertise2013
url: https://roamresearch.com/#/app/megacoglab/page/9nBbrKdGs
author: Joel Chan
date: Tue Feb 11 2020 15:50:25 GMT-0500 (Eastern Standard Time)
---

- #references

    - Title: Sharing Knowledge and Expertise: The CSCW View of Knowledge Management

    - Meta:

        - Tags:: #[[references]] #[[D/Synthesis Infrastructure]] #[[D/KNEXT]] #ref/Paper

        - Authored by::  [[Mark Ackerman]] ,  Juri Dachtera ,  Volkmar Pipek ,  [[Volker Wulf]]

        - Year: [[2013]]

        - Publication: [[Computer Supported Cooperative Work (CSCW)]]

    - Content:

        - :hiccup [:iframe {:width "650px", :height "650px", :src "https://drive.google.com/file/d/1e0TVK1wYSxCwDkskVnmCMLsZlDWQA_7j/preview"}]

    - #lit-context

        - #canonical paper in the lab

    - #[[üìù lit-notes]]

        - [[[[CLM]] - CSCW research on knowledge sharing shifted from a repository model to an expertise sharing model around the mid-2000's - [[@ackermanSharingKnowledgeExpertise2013]]]]

            - In general, CSCW research on knowledge sharing has moved from a "repository model", which focused on externalizing knowledge in documents and databases, to an "expertise sharing" model, which focuses on helping people find relevant knowledge from other knowledgeable people directly  p.532-533

            - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FHc-RAqA1r5?alt=media&token=6554ee91-3cff-4f5b-a346-6ba0cb8764e1)

        - The shift from the "[[repository model]]" of CSCW work to focus on "[[expertise sharing]]" was stimulated in large part by rich discoveries about the large extent to which useful knowledge is tacit and situated #[[tacit knowledge]] p.547

            - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2Fj8jz9iLumu?alt=media&token=aad30f8d-15a6-4ce2-8d6d-f0040f7dcb90)

            - Cites [[@starInstitutionalEcologyTranslations1989]] to note that [[[[PTN]] - boundary object]]s were a key learning from the first generation "repository models" to motivate the shift to [[Expertise Sharing]]

                - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FNytKlvx_Gq.png?alt=media&token=03824ef6-44f8-4172-8c54-b8dc04c83bd7)

                - [[[[PTN]] - boundary object]]s derive part of their power (for facilitating cross-organizational/boundary coordination and work) by being "weakly structured in common use, and strongly structured in specific use"

        - [[[[CLM]] - Specifying context for future reuse is costly]]

            - #ClaimSecondary people find adding meta-data to be laborsome [[@hinrichsContextGrabbingAssigning2005]]

                - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FFvtyx1Wepe.png?alt=media&token=fee6554d-969c-4033-a6b7-b6b9d5e5a32b) (p. 540)

            - #ClaimSecondary people tend to use the category with the lowest cognitive effort [[@andersonDataBaseMent2008]]

                - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FFvtyx1Wepe.png?alt=media&token=fee6554d-969c-4033-a6b7-b6b9d5e5a32b) (p. 540)

                - [[@andersonDataBaseMent2008]] call these "residual categories"

                - it can be quite hard to standardize (and therefore make efficient) expressions of [[context]] (e.g., in a dropdown menu of possible "contexts")

###### Discourse Context

- **Informs::** [[CLM - Knowledge must be recontextualized to be usefully reused]]
- **Informs::** [[CLM - Specifying context for future reuse requires predicting trajectories of future reuse]]
- **Informs::** [[CLM - Distinction between neat vs scruffy in Semantic Web engineering]]
- **Informs::** [[CLM - CSCW research on knowledge sharing shifted from a repository model to an expertise sharing model around the mid-2000's - @ackermanSharingKnowledgeExpertise2013]]
- **Informs::** [[CLM - Substantial portions of knowledge that is critical for innovation are not written down]]
- **Informs::** [[QUE - How can we best bridge private vs. public knowledge]]
- **Informs::** [[QUE - What are the most efficient routes to useful cross-boundary knowledge]]

###### References

[[July 12th, 2020]]

- is it a fool's errand to try to combine these repeated insights (see [[communities of practice]], [[Cynefin model]], [[@ackermanSharingKnowledgeExpertise2013]], etc.) about the [[context]]ual and situated nature of knowledge with the project of a [[Semantic Web]]? situated semantic webs?

    - quick search for intersection of situated cognition and semantic web, and i'm not really seeing any coherent body of work. not sure if i'm looking in the right place, though.

        - https://scholar.google.com/scholar?hl=en&as_sdt=0%2C21&q=situated+cognition+semantic+web&btnG=

        - on [[sys/ConnectedPapers]]: https://www.connectedpapers.com/main/4a49c51b6a17a41e7634c0d169915e0e18bbbb78/Situated-Cognition-in-the-Semantic-Web-Era/graph

            - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FI5I_fyoBpM.png?alt=media&token=69f993f3-1eae-4e96-aeaf-c67594f20256)
[[January 26th, 2021]]

- Significant work across formal conceptual models of scholarly argumentation [[@deWaardProteinsFairytalesDirections2010]], [[@clarkMicropublicationsSemanticModel2014]], sensemaking [[@russellCostStructureSensemaking1993]], and knowledge management [[@ackermanSharingKnowledgeExpertise2013]] suggest that an optimal information model for supporting synthesis is the epistemic model: shareable collections of knowledge __claims__ (e.g., __children are less susceptible to COVID-19 infection, given equivalent exposure__) and their associated __context__ (e.g., \textit{was sampling symptom-based? Where was the study conducted? At what point in the locality's epidemic time course?}), \textit{connected} in a discourse graph (e.g., supporting other hypotheses/claims, corroborated/disputed by other claims).

    - Key hypothesized affordances of [[[[PTN]] - discourse graph]] include the ability to compress complex ideas into granular statements, which affords quicker comparison, comprehension, and composition of ideas, while also retaining links to contextual details to allow for "unpacking" and critical interrogation of ideas as they are interpreted and recombined into more complex arguments/models.

    - These affordances are hypothesized to enable key process-level interactions with scholarly knowledge that are crucial for synthesis, such as a principled dialectic between context-rich observations (data) and creative and formal construction of models and hypotheses (theory).

    - These affordances may also enable more effective reuse and remixing of ideas across boundaries of time, projects, and even collaborators.
[[January 27th, 2021]]

- Significant work across formal conceptual models of scholarly argumentation [[@deWaardProteinsFairytalesDirections2010]], [[@clarkMicropublicationsSemanticModel2014]], sensemaking [[@russellCostStructureSensemaking1993]], and knowledge management [[@ackermanSharingKnowledgeExpertise2013]] suggest that an optimal information model for supporting synthesis is a collection of knowledge **claims** and their associated __context__, __connected__ in a discourse graph.

    - The answers to these questions cannot be found simply in the titles of research papers, in groupings of papers by area, or even in citation or authorship networks (effective though they might be at revealing macro structures in scientific communities). These information structures are not at the desired level of granularity, which is at the level of theoretical concepts/claims and empirical **claims** and evidence: for example, "__game theory predicts that discourse can devolve to an escalating tit-for-tat spiral under X conditions__", or "__banning bad actors from a subreddit in 2012 was somewhat effective at mitigating spread of misinformation on the subreddit__". This level of granularity is crucial not just for finding relevant claims to inform the synthesis, but also for constructing more complex arguments and theories (by connecting statements in logical and discursive relationships).

    - To understand why this information model is hypothesized to augment synthesis, let us return to our motivating example of the researcher who wants to design new interventions to mitigate online harassment. To synthesize a formulation of this problem that can advance the state of the art, she needs material that can help her work through detailed answers to a range of granular questions. For example, what theories of online behavior and antisocial behavior might be most relevant for understanding what is going on here? Which theories have the most empirical support in this particular setting? Are there conflicting theoretical predictions that might signal fruitful areas of inquiry? What are the key phenomena to keep in mind when designing an intervention (e.g., perceptions of human vs. automated action, procedural considerations, noise in judgments of wrongdoing, scale considerations for spread of harm)? What intervention patterns have been proposed that are both a) judged on theoretical and circumstantial grounds as likely to be effective in this setting, and b) lacking in direct evidence for efficacy?

    - Beyond operating at the claim level, however, our researcher will need to work through a range of **contextual details**. For example, to judge which studies and findings/theories are "actually applicable" (e.g.,, studying similar populations, interventions, settings, or outcome measures?) to her setting, she might need to reason over the fact that two studies that concluded limited efficacy of bans had ban interventions that were quite short, on a forum with no identity verification. Or she might reason through the fact that a prominent theory of bad faith and discourse was proposed by a philosopher from the early 2000's (before the rise of modern social media). To judge the validity of past findings (e.g., what has been established with sufficient certainty, where the frontier might be), she would need to know, for example, which findings came from which measures (e.g., self-report, behavioral measures), and the extent to which findings have been replicated cross authors from different labs, and across a variety of settings.

    - Also, contextual details, such as methodology or metadata, are explicitly included in the discourse graph. This should support direct analysis of claims with their evidentiary context. Figure X shows how this might be supported in the specific worked example above.

    - Beyond these direct hypothesized benefits to synthesis, such models could also be used and repurposed over time, across projects, and potentially even across people. For example, imagine collaborators sharing these collections of epistemic models with each other, to speed up the process of working towards shared mental models and identify productive areas of divergence; or PIs and senior students onboarding newer students not with long reading lists, but subsets of epistemic models that they can build on and add to over time. How much time and overhead could be saved if this were a reality?

    - An epistemic model has key affordances that are hypothesized to enable just these sorts of operations. Information is represented primarily at the claim/statement level, and are embedded in a discourse graph. Thus, claims should be able to have many-to-many relationships to support composition of more complex arguments and theories, or "decompression" into component supporting/opposing claims.
[[CL - Compression and contextualizability are in tension]]

- This process of removing details is studied by [[CSCW]] in the context of Knowledge [[reuse]]: the rich history of studies here emphasize that [[decontextualization]] ---removing extraneous details from a description of a knowledge object --- is a necessary precondition for [[reuse]], across organizational/social boundaries and time [[@ackermanSharingKnowledgeExpertise2013]].

    - In [[CSCW]] theories of knowledge reuse, there is a related idea of [[decontextualization]], where a bit of knowledge has to be stripped of "irrelevant" details in order to become useful in organizational contexts across boundaries.

        - Decontextualization allows knowledge to be stored and passed across organizational boundaries, enabling coordination.
[[@ackermanSharingKnowledgeExpertise2013]]

- [[[[CLM]] - CSCW research on knowledge sharing shifted from a repository model to an expertise sharing model around the mid-2000's - [[@ackermanSharingKnowledgeExpertise2013]]]]

    - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FHc-RAqA1r5?alt=media&token=6554ee91-3cff-4f5b-a346-6ba0cb8764e1)

    - In general, CSCW research on knowledge sharing has moved from a "repository model", which focused on externalizing knowledge in documents and databases, to an "expertise sharing" model, which focuses on helping people find relevant knowledge from other knowledgeable people directly  p.532-533
[[John Thesis]]

- #[[@ackermanSharingKnowledgeExpertise2013]]

    - older information artifacts may be difficult to recontextualize and [[authoritativeness/reliability]] may not be able to be evaluated (due to the age of the artifact?)
[[May 25th, 2020]]

- Looking through the stuff on [[context]] brought back up [[@ackermanSharingKnowledgeExpertise2013]], which reminded me of the [thread]( for when I pick up [[P: KNEXT System Prototype]] again: prior art on how libraries can engage with online communities) on [[P: KNEXT System Prototype]]

    - ‚û∞ breadcrumbs Sparked me to reify this idea we've been kicking around for awhile, and what I think initially drew me to the [[D/KNEXT]] project: [[P: Libraries supercharging communities of practice]]

        - This is an interesting nuance on the idea of [[Library 2.0]] and [[Community-Centered Libraries]] because it draws on the rich tradition of [[communities of practice]]

        - I'm reminded also of [[Joohee Choi]]'s findings about [[Z: Tagging is essential but unrewarded work in online knowledge sharing communities]]

        - There is also a connection to #[[[[PTN]] - Organize by using]]

            - Now also thinking of that one book on library of congress and [[@ adlerCruisingLibraryPerversities2017]] has a wonderful #example-of the profound consequences of seemingly mundane [[Classification]] decisions (i.e., [[infrastructure]]). They're focused on the consequences for social justice, but the consequences for siloing knowledge and contributing to [[Scatter]] (because of hte nature of a filing/classification system) are plain to me too.

        - Lots of nuances!

            - [[embedded librarianship]] is a thing too. Not sure again about connection to [[communities of practice]] lit. [[Lisa Feldman-Barrett]] is a close-ish contact who does this. I think the goal is slightly different too? More about [[formality]] and focused on information resources, less on the community / network of people.

        - I really like how this puts an interesting spin on the idea of knowledge extension. :)

        - Important leads:

            - Small-ish lit seems like: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C21&q=librarian+community+of+practice&btnG= - lots of studies of [[communities of practice]] *for* librarians, but not necessarily the other way

                - #[[@jager-loftusCommunityPracticeLibrarians2014]] Title: A Community of Practice: Librarians in a Biomedical Research Network (community *of* librarians, not cultivated *by* librarians)

                - #[[@cliftonCultivatingCommunityPractice2017]] Title: Cultivating a community of practice: the evolution of a health information specialists program for public librarians

            - Some exceptions:

                - #[[@radfordSharedValuesNew2017]] connects [[communities of practice]] to the practice of virtual reference services. Quite close to what we are thinking of. [[m/Semi-structured interviews]]

                - For faculty / campus

                    - #[[@miExpandingLibrarianRoles2015]] case study of a librarian initiating and cultivating a [[communities of practice]] on campus; lessons learned, etc.

        - One interesting nuance too is [[I wonder]] what the role of librarians could be in supercharging [[communities of practice]]. My current mostly uninformed impression is that they don't seem to have mixed much in the past.

        - [[communities of practice]] have been studied in a more descriptive fashion, probably the role of [[guilds]] has been studied, but not sure about specific ideas of cultivating COP, and whether librarians have an interesting role of play.
[[July 20th, 2020]]

- #CLlaimSecondary from [[@ackermanSharingKnowledgeExpertise2013]] about [[[[CLM]] - Specifying context for future reuse is costly]]

    - Since [[[[CLM]] - Context is a slippery notion]], which means ((pLB5JYk-W)) [[@andersonDataBaseMent2008]]

        - A fundamental insight for [[[[PTN]] - flexible compression]] could go further than a priori specification: [[context]] is always specified (reified?) **at use time** (i.e., [[context]]ually with specific [[context queries]])

    - The claims

        - #ClaimSecondary people find adding meta-data to be laborsome [[@hinrichsContextGrabbingAssigning2005]]

        - #ClaimSecondary people tend to use the category with the lowest cognitive effort [[@andersonDataBaseMent2008]]
[[July 8th, 2020]]

- [[Cynefin model]] (see [[@snowdenComplexActsKnowing2002]]) is entry point into [[Knowledge Management]] lit that echoes a lot of what was described in [[@ackermanSharingKnowledgeExpertise2013]], but from a (very? no citations of [[David Snowden]] at all in ackerman) different lineage, a lot running through knowledge management proper, and involving other canonical ideas like the [[SECI model]] and this influential [[Cynefin model]] from [[David Snowden]], less so [[[[PTN]] - boundary object]]s and the like from CSCW.

    - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FYIOGpFykZS.png?alt=media&token=27b439b3-0cb2-4f61-8bfa-711fc7d75182)

    - This stuff is actually hugely foundational, for both [[D/KNEXT]] and [[D/Synthesis Infrastructure]]. In some ways, a core defining concern of mine is [[Knowledge Management]] for creative work. And [[D/Synthesis Infrastructure]] is really about [[Knowledge Management]] but for scientific discovery and [[synthesis]]?
[[@andersonDataBaseMent2008]]

- cited in [[@ackermanSharingKnowledgeExpertise2013]]

    - #ClaimSecondary people tend to use the category with the lowest cognitive effort [[@andersonDataBaseMent2008]]
[[December 1st, 2020]]

- A fundamental remaining problem is how to motivate and support **sharing** of these often private and informal intermediate products. Past efforts have discovered significant costs of predicting and capturing contextual details [[@ackermanSharingKnowledgeExpertise2013]], as well as challenges motivating contributions to an abstract and distant "community" with limited immediate benefits. Therefore, we propose to explore a local semantic publishing model, consisting of three main components:

    - Integration points for sharing in existing collaborative practices, such as journal clubs, conference discussions, and lab discussions.

    - Novel interfaces that directly improve synthesis for the sharer

        - same here, can first integrate into a [[hypertext notebooks]]

            - but later build as a chrome extension or word plugin - essentially like an enhanced "search/scatter-gather" interface to find things to insert and compare

        - these all seem simple, but that is the point! they are simple yet extremely powerful

    - Novel augmentations of familiar tools that lower the costs of creating shareable representations (key cost is identifying and attaching context). We build on our preliminary work in [[@qianITunesPapersRedefining2019a]]

        - it turns out that a suped up PDF reader (with connections to open annotations like [[sys/Hypothes.is]]), so that the annotations are hyperlinkable, and a notetaking system with [[std/Hypertext]] affordances (like [[hypertext notebooks]]) are probably sufficient to produce the kinds of things we want

            - it's also technically feasible to move some of the hypertext affordances like [[bi-directional links]] and [[transclusion]] into something like Google Docs

            - and people are familiar with these affordances already, thanks to the ubiquity of [[sys/Wiki]]s
[[February 16th, 2021]]

- Augment with [[reuse]] CSCW [[@ackermanSharingKnowledgeExpertise2013]]

    - much more on [[context]]

    - but also hints that [[[[CL]] - Compression and contextualizability are in tension]]
