---
title: @zhuGenerativePreTrainedTransformer2021
url: https://roamresearch.com/#/app/megacoglab/page/UR0Nu_XIF
author: Jason Ding
date: Thu Mar 17 2022 23:47:19 GMT-0400 (Eastern Daylight Time)
---

- Title:: Generative Pre-Trained Transformer for Design Concept Generation: An Exploration
- Author(s):: [[Qihao Zhu]], [[Jianxi Luo]]
- Abstract:: Novel concepts are essential for design innovation and can be generated with the aid of data stimuli and computers. However, current generative design algorithms focus on diagrammatic or spatial concepts that are either too abstract to understand or too detailed for early phase design exploration. This paper explores the uses of generative pre-trained transformers (GPT) for natural language design concept generation. Our experiments involve the use of GPT-2 and GPT-3 for different creative reasonings in design tasks. Both show reasonably good performance for verbal design concept generation.
- Type:: [[Article]]
- Publication:: arXiv:2111.08489 [cs]
- URL : http://arxiv.org/abs/2111.08489
- Date Added:: [[March 14th, 2022]]
- Zotero links:: [Local library](zotero://select/groups/2451508/items/FZ6QIWK7), [Local library](https://www.zotero.org/groups/2451508/items/FZ6QIWK7)
- Tags:: #[[Computer Science - Computation and Language]], #[[Computer Science - Machine Learning]]
- PDF links : [Zhu and Luo - 2021 - Generative Pre-Trained Transformer for Design Conc.pdf](zotero://open-pdf/groups/2451508/items/535XGYHJ)
- [[Notes]]

    - Comment: Submitted to the DESIGN 2022 Conference
- [[Jason Ding]] for <what, e.g., the que we wanted to read this for> | __<summary of what was learned in this session (fill this out later)>__

    - method for [[prompt programming]] with [[sys/GPT-3]]: "apply {source_domain} to {target_domain}" is the prompt

        - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2F2S3fB-OAXI.png?alt=media&token=2baed93a-84e9-40b8-8242-be873022a449)

    - Given that GPT-3 was released in 2020, up to Mar 2022 there are few papers adapting GPT-3 to the design domain. This preprint discusses their practice of using GPT-3 for natural language design concept generation, and reasonable good performance for verbal design concept generation were observed (evidences are provided later). The way they used GPT-3 for problem solving is analogy-driven reasoning: projecting an existing reference in a source domain to address a comparable challenge in the target domain. Leveraging GPT-3â€™s capability of few-shot learning, a few design-by-analogy examples could empower GPT-3 to generate ideas in the target domains based on input source domains. Below are the four ideas (concepts) of drones (target domain) generated by GPT-3 based on source domains (lantern and origami):'

        - ![](https://lh5.googleusercontent.com/eBgkOsBEE6iKDDw5oie4_Ug1vdcTeJwsDC_ZECpomCBN1fx-2UAYXKYfacp2_3d-7g2x00ptUDwIUXfGg7rENU4zyISXgJDxt8f66NfpPcr9DD3kzGu8NzyhVVw4tvhqN3tiypmx)

    - ## results of interest and discussion - none (no formal analysis, just proof of concept of some outputs)

        - __One block for each result of interest. we'll refactor this together into EVD notes__

            - ### summary

                - __nest details and screenshots (e.g., key figures, quotes) under here__

            - ### grounding context

                - __block ref in major methods details from the source methods / context block we might need later to make sense of this result, particularly as they might conflict with others. __

            - __also discuss possible critiques/claims. create source CLM notes for author conclusions (if you like), or reference other CLMs that we have that engage with this__

        - __Also can discuss meta-results (combinations of results) in a similar template.____

    - ## side notes

        - __Where are the authors coming from? Are there any useful "breadcrumbs" (e.g., other theoretical frameworks, authors, papers) we can follow up on?__

###### Discourse Context


