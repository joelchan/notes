---
title: @ramageLabeledLDASupervised2009
url: https://roamresearch.com/#/app/megacoglab/page/CLFykisX_
author: Joel Chan
date: Mon Oct 26 2020 23:09:40 GMT-0400 (Eastern Daylight Time)
---



###### Discourse Context



###### References

[[October 26th, 2020]]

- [[@ramageLabeledLDASupervised2009]]

    - #[[references]]

        - Title: Labeled LDA: A Supervised Topic Model for Credit Attribution in Multi-labeled Corpora

        - Meta:

            - Authored by:: [[Daniel Ramage]] [[David Hall]] [[Ramesh Nallapati]] [[Christopher D. Manning]]

            - Year: [[2009]]

            - Publication: Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1

            - Zotero link: [Zotero Link](zotero://select/items/1_RM4FPMA4)

            - URL: [Ramage et al. (2009). Labeled LDA: A Supervised Topic Model for Credit Attribution in Multi-labeled Corpora. Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1](http://dl.acm.org/citation.cfm?id=1699510.1699543)

        - Content

            - Abstract

                - A significant portion of the world's text is tagged by readers on social bookmarking websites. Credit attribution is an inherent problem in these corpora because most pages have multiple tags, but the tags do not always apply with equal specificity across the whole document. Solving the credit attribution problem requires associating each word in a document with the most appropriate tags and vice versa. This paper introduces Labeled LDA, a topic model that constrains Latent Dirichlet Allocation by defining a one-to-one correspondence between LDA's latent topics and user tags. This allows Labeled LDA to directly learn word-tag correspondences. We demonstrate Labeled LDA's improved expressiveness over traditional LDA with visualizations of a corpus of tagged web pages from del.icio.us. Labeled LDA outperforms SVMs by more than 3 to 1 when extracting tag-specific document snippets. As a multi-label text classifier, our model is competitive with a discriminative baseline on a variety of datasets.
