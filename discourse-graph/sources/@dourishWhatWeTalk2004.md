---
title: @dourishWhatWeTalk2004
url: https://roamresearch.com/#/app/megacoglab/page/4SafY60Wi
author: Joel Chan
date: Wed May 20 2020 11:20:00 GMT-0400 (Eastern Daylight Time)
---

- #references

    - Title: What we talk about when we talk about context

    - Meta:

        - Tags: #ref/Paper

        - Authored by::  [[Paul Dourish]]

        - Year: [[2004]]

        - Publication: Personal and Ubiquitous Computing

        - URL: https://doi.org/10.1007/s00779-003-0253-8

        - Citekey: dourishWhatWeTalk2004

    - Content

        - :hiccup [:iframe {:width "650px", :height "650px", :src "https://drive.google.com/file/d/1nuZ6EzJvMuNNhFC_P5xPsSzmGXbmosNF/preview"}]

    - #lit-context

        - Classic #canonical paper about [[context]] within [[Ubiquitous Computing]]

            - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FjB4WPv_NGL.png?alt=media&token=cdbc182d-1e96-403b-91a3-133a24e209aa)

    - #[[📝 lit-notes]]

        - #> "It is not simply the case that something is or is not context; rather, it may or may not be contextually relevant to some particular activity." #context (p.22)

            - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2Faqn80NOXrD.png?alt=media&token=45ba2059-7ef5-4a27-a3b9-4294e98e3352)

###### Discourse Context

- **Informs::** [[CLM - Context is a slippery notion]]
- **Informs::** [[CLM - Knowledge is fundamentally contextual]]
- **Informs::** [[QUE - How can we best bridge private vs. public knowledge]]

###### References

[[May 20th, 2020]]

- [[@dourishWhatWeTalk2004]]

    - Could have sworn I've seen this paper before: why isn't it in my collection? Where is it??? Haha. POrobably in evernote?

        - Ah indeed in Evernote

            - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fmegacoglab%2FcpFqc0lkjT.png?alt=media&token=10d95dbb-924e-43d5-8185-5fbdbe21852b)

        - Nice #example-of something that was "lost" but not really "lost" (came back around eventually). Q is how much was lost in the meantime.

    - anyway, #[[➰ breadcrumbs]] this is a foundational paper to deep-read and create lit-notes on for [[[[CLM]] - Contextualizability is necessary for synthesis]], along with [[@ackermanOrganizationalMemoryObjects2004]] and [[@luttersBoundaryObjectsCollaborative2007]]
[[July 18th, 2020]]

- [[@dourishWhatWeTalk2004]] would likely bristle at the prospect of somehow enumerating possible sets of [[context]]-relevant information bits to make available for [[[[PTN]] - flexible compression]].

    - At minimum, we should be careful not to make [[one-to-one]] mappings between some feature and whether it is or isn't [[context]]

    - One salient point to keep in mind is that [[[[CLM]] - Context is a slippery notion]].

    - This doesn't mean the task is impossible. We just shouldn't be naive about it.
