---
title: @brownLanguageModelsAre2020
url: https://roamresearch.com/#/app/megacoglab/page/FOlF6PJzi
author: Jason Ding
date: Thu Nov 04 2021 19:46:28 GMT-0400 (Eastern Daylight Time)
---

- Title: Language Models are Few-Shot Learners
- Meta:

    - Tags: #ref/Paper

    - Authored by::  [[[Tom B. Brown]], et al.

    - Year: [[2020]]

    - URL: [Brown et al. (2020) Language Models are Few-Shot Learners.](https://arxiv.org/abs/2005.14165)

    - Citekey: brownLanguageModelsFew2020
- Content

    - Abstract

        - Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.
- Title:: Language Models are Few-Shot Learners
- Author(s):: [[Tom B. Brown]], [[Benjamin Mann]], [[Nick Ryder]], [[Melanie Subbiah]], [[Jared Kaplan]], [[Prafulla Dhariwal]], [[Arvind Neelakantan]], [[Pranav Shyam]], [[Girish Sastry]], [[Amanda Askell]], [[Sandhini Agarwal]], [[Ariel Herbert-Voss]], [[Gretchen Krueger]], [[Tom Henighan]], [[Rewon Child]], [[Aditya Ramesh]], [[Daniel M. Ziegler]], [[Jeffrey Wu]], [[Clemens Winter]], [[Christopher Hesse]], [[Mark Chen]], [[Eric Sigler]], [[Mateusz Litwin]], [[Scott Gray]], [[Benjamin Chess]], [[Jack Clark]], [[Christopher Berner]], [[Sam McCandlish]], [[Alec Radford]], [[Ilya Sutskever]], [[Dario Amodei]]
- Abstract:: Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.
- Type:: [[Article]]
- Publication:: arXiv:2005.14165 [cs]
- URL : http://arxiv.org/abs/2005.14165
- Date Added:: [[July 31st, 2021]]
- Zotero links:: [Local library](zotero://select/groups/2451508/items/J2CBTDKN), [Local library](https://www.zotero.org/groups/2451508/items/J2CBTDKN)
- Tags:: #[[Computer Science - Computation and Language]]
- [[Notes]]

    - Comment: 40+32 pages

###### Discourse Context

- **Informs::** [CLM - transformer language models have some analogical reasoning ability.md](CLM - transformer language models have some analogical reasoning ability.md)
- **Informs::** [QUE - Can deep learning discover analogical representations.md](QUE - Can deep learning discover analogical representations.md)
- **Informs::** [QUE - What do we know about transformer language models' natural language generation capabilities.md](QUE - What do we know about transformer language models' natural language generation capabilities.md)

